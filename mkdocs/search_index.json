{
    "docs": [
        {
            "location": "/",
            "text": "SERPS\n\n\nThe PHP Search Engine Result Page Spider\n\n\n\n\n\n\nSERPS is a scraping library for php. It considerably decrease the complexity required to analyse search engines.\n\n\n\n\nWeb scraping\n (web harvesting or web data extraction) is a computer software technique of extracting \ninformation from websites. Usually, such software programs simulate human exploration of the World Wide Web \nby either implementing low-level Hypertext Transfer Protocol (HTTP), \nor embedding a fully-fledged web browser, such as Mozilla Firefox.\n\n\nWikipedia\n\n\n\n\nWhat is it?\n\n\nSerps is a set of tools that ease the parsing of \npopular search engines\n (such as google, yahoo or bing).\nIt helps to parse \nSERP\n (Search Engine Result Page) and gives you a standard output of what is parsed.\n\n\nThe problem\n\n\nMost of times search engines don't want you to parse them, and they don't offer a documentation or a standard way \nto extract the results from the SERP and it's hard to write and maintain a scraper.\n\n\nThe solution\n\n\nTo solve this problems we \nanalysed\n how search engines behave and we built the necessary tools to\nwork with them, from the URL generation to the parsing of the results. \nAt the endpoint we offer a \nstandard and documented API\n.\n\n\nGetting Started\n\n\nLooking forward to work with the library? \n\n\n\n\nStart with the \noverview\n.\n\n\nBrowse the available \nsearch engines\n and \nhttp clients\n from the top menu.\n\n\n\n\nSupport & issue \n\n\nYou have problems to get started with the library or you have general question? We'd like to hear about,\n\njoin us on gitter\n.\n\n\nYou spotted an issue with the library? Please report it on the \n\ngithub issue tracker\n.\n\n\nSponsored By\n\n\n\n\nThe project has been sponsored by \nMondovo.com\n\n\nLicensing\n\n\nThe work is placed under the terms of the \nFair License\n.\n\n\n\n\nUsage of the works is permitted provided that this instrument is retained with the works, \nso that any entity that uses the works is notified of this instrument.\n\n\nDISCLAIMER: THE WORKS ARE WITHOUT WARRANTY.",
            "title": "Home"
        },
        {
            "location": "/#serps",
            "text": "The PHP Search Engine Result Page Spider    SERPS is a scraping library for php. It considerably decrease the complexity required to analyse search engines.   Web scraping  (web harvesting or web data extraction) is a computer software technique of extracting \ninformation from websites. Usually, such software programs simulate human exploration of the World Wide Web \nby either implementing low-level Hypertext Transfer Protocol (HTTP), \nor embedding a fully-fledged web browser, such as Mozilla Firefox.  Wikipedia",
            "title": "SERPS"
        },
        {
            "location": "/#what-is-it",
            "text": "Serps is a set of tools that ease the parsing of  popular search engines  (such as google, yahoo or bing).\nIt helps to parse  SERP  (Search Engine Result Page) and gives you a standard output of what is parsed.",
            "title": "What is it?"
        },
        {
            "location": "/#the-problem",
            "text": "Most of times search engines don't want you to parse them, and they don't offer a documentation or a standard way \nto extract the results from the SERP and it's hard to write and maintain a scraper.",
            "title": "The problem"
        },
        {
            "location": "/#the-solution",
            "text": "To solve this problems we  analysed  how search engines behave and we built the necessary tools to\nwork with them, from the URL generation to the parsing of the results. \nAt the endpoint we offer a  standard and documented API .",
            "title": "The solution"
        },
        {
            "location": "/#getting-started",
            "text": "Looking forward to work with the library?    Start with the  overview .  Browse the available  search engines  and  http clients  from the top menu.",
            "title": "Getting Started"
        },
        {
            "location": "/#support-issue",
            "text": "You have problems to get started with the library or you have general question? We'd like to hear about, join us on gitter .  You spotted an issue with the library? Please report it on the  github issue tracker .",
            "title": "Support & issue "
        },
        {
            "location": "/#sponsored-by",
            "text": "The project has been sponsored by  Mondovo.com",
            "title": "Sponsored By"
        },
        {
            "location": "/#licensing",
            "text": "The work is placed under the terms of the  Fair License .   Usage of the works is permitted provided that this instrument is retained with the works, \nso that any entity that uses the works is notified of this instrument.  DISCLAIMER: THE WORKS ARE WITHOUT WARRANTY.",
            "title": "Licensing"
        },
        {
            "location": "/overview/",
            "text": "Overview\n\n\nThis overview will help you to understand how the library is built and what are its main components.\n\n\n\n\nInstall\n\n\nTo work with SERPS you need two things:\n\n\n\n\nOne or more search engine clients you want to parse\n\n\nA http client\n\n\n\n\nIn addition \nComposer\n is required to manage the necessary dependencies.\n\n\n\n\ncomposer.json example with the \nGoogle client\n and the \nCurl http client\n\n\n\n\n{\n    \"require\": {\n        \"serps/core\": \"*\",\n        \"serps/search-engine-google\": \"*\",\n        \"serps/http-client-curl\": \"*\"\n    }\n}\n\n\n\n\n\n\nDanger\n\n\nThe library is still in alpha, no version is released yet that means that minor things can change until \nthe stable release and your code might become not compatible with the updates.\n\n\n\n\nSearch Engine client\n\n\nIn a regular workflow a search engine client allows to:\n\n\n\n\nManipulate an url and generate a request specific to the search engine\n\n\nRetrieve the response from the search engine\n\n\nParse this response to a standard sets of results\n\n\n\n\nEach \nsearch engine\n has its set of specificities and thus each search engine implementation has its own dedicated guide.\n\n\nThese search engines are currently available:\n\n\n\n\nGoogle\n\n\n\n\nHttp Client\n\n\nWorking with search engines involves to work with \nhttp requests\n.\nUsually the \nsearch engine client\n will need a http client to work correctly.\n\n\n\n\nExample with the \ngoogle client\n and the \ncurl http client\n\n\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n\n\n\nThere are two kinds of http clients: those that return the raw html as returned from the search engine (e.g the curl client)\nand the others that evaluate the javascript and update the DOM before before returning (e.g the phantomJS client)\n\n\nThese http clients are currently available:\n\n\n\n\nRaw clients:\n\n\nCURL\n\n\n\n\n\n\nEvaluating clients\n\n\nphantomJS\n\n\n\n\n\n\n\n\nProxies\n\n\nMost of time search engines don't want you to parse them thus \nthey use to block you with captcha when they think you are a bot\nWhen you deal with a very \nlarge number of requests\n, you will need to send requests\nthrough proxies.\n\n\nThis is a major feature of scraping and we placed proxies at the very heart of the library. \nEach request is proxy aware. \nThis way, with a single client you can use as many proxies as you want.\n\n\n\n\nExample of \nproxy\n usage with the google client\n\n\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleClient->query($googleUrl, $proxy);\n\n\n\n\nRead the \nproxy doc\n to learn more about proxy creation.\n\n\nCaptcha\n\n\nEven though you are using proxies and place all the efforts to act like an human, you might encounter the fatal captcha.\n\n\nWhen you get \nblocked\n by a captcha request, it is very important to stop sending request to the search engine and to\nsolve the captcha before you continue. \n\n\nDealing with captcha is not easy, at the current state the library can detect captcha but is not able to solve them\nfor you we are \ncurrently working\n on a captcha solver implementation.\n\n\n\n\nNote\n\n\nCaptcha are proxy specific, when solving a captcha that should be done with the proxy that was initially blocked\n\n\n\n\nCookies\n\n\nSERPS integrates cookie management, that allows to share cookies across many requests.\n\n\nCookie management is usually done at the search engine client level. You still want to know\nhow to manipulate cookies and cookiejars: \n\nsee cookie documentation",
            "title": "Overview"
        },
        {
            "location": "/overview/#overview",
            "text": "This overview will help you to understand how the library is built and what are its main components.",
            "title": "Overview"
        },
        {
            "location": "/overview/#install",
            "text": "To work with SERPS you need two things:   One or more search engine clients you want to parse  A http client   In addition  Composer  is required to manage the necessary dependencies.   composer.json example with the  Google client  and the  Curl http client   {\n    \"require\": {\n        \"serps/core\": \"*\",\n        \"serps/search-engine-google\": \"*\",\n        \"serps/http-client-curl\": \"*\"\n    }\n}   Danger  The library is still in alpha, no version is released yet that means that minor things can change until \nthe stable release and your code might become not compatible with the updates.",
            "title": "Install"
        },
        {
            "location": "/overview/#search-engine-client",
            "text": "In a regular workflow a search engine client allows to:   Manipulate an url and generate a request specific to the search engine  Retrieve the response from the search engine  Parse this response to a standard sets of results   Each  search engine  has its set of specificities and thus each search engine implementation has its own dedicated guide.  These search engines are currently available:   Google",
            "title": "Search Engine client"
        },
        {
            "location": "/overview/#http-client",
            "text": "Working with search engines involves to work with  http requests .\nUsually the  search engine client  will need a http client to work correctly.   Example with the  google client  and the  curl http client       use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n\n    $googleClient = new GoogleClient(new CurlClient());  There are two kinds of http clients: those that return the raw html as returned from the search engine (e.g the curl client)\nand the others that evaluate the javascript and update the DOM before before returning (e.g the phantomJS client)  These http clients are currently available:   Raw clients:  CURL    Evaluating clients  phantomJS",
            "title": "Http Client"
        },
        {
            "location": "/overview/#proxies",
            "text": "Most of time search engines don't want you to parse them thus \nthey use to block you with captcha when they think you are a bot\nWhen you deal with a very  large number of requests , you will need to send requests\nthrough proxies.  This is a major feature of scraping and we placed proxies at the very heart of the library. \nEach request is proxy aware. \nThis way, with a single client you can use as many proxies as you want.   Example of  proxy  usage with the google client       use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleClient->query($googleUrl, $proxy);  Read the  proxy doc  to learn more about proxy creation.",
            "title": "Proxies"
        },
        {
            "location": "/overview/#captcha",
            "text": "Even though you are using proxies and place all the efforts to act like an human, you might encounter the fatal captcha.  When you get  blocked  by a captcha request, it is very important to stop sending request to the search engine and to\nsolve the captcha before you continue.   Dealing with captcha is not easy, at the current state the library can detect captcha but is not able to solve them\nfor you we are  currently working  on a captcha solver implementation.   Note  Captcha are proxy specific, when solving a captcha that should be done with the proxy that was initially blocked",
            "title": "Captcha"
        },
        {
            "location": "/overview/#cookies",
            "text": "SERPS integrates cookie management, that allows to share cookies across many requests.  Cookie management is usually done at the search engine client level. You still want to know\nhow to manipulate cookies and cookiejars:  see cookie documentation",
            "title": "Cookies"
        },
        {
            "location": "/browser/",
            "text": "Browser\n\n\nGuide for browser instance management \n\n\n\n\nIn SERPS the \nbrowser\n is an element that helps to mimic the behavior of a browser. \n\n\nBe aware that the name browser stand for the fact that this entity is capable of emitting http request as a real\nbrowser would do, taking care of cookies, proxies, language, etc... but \nin any case\n this class is able\nto render a html page or to evaluate css or javascript.\n\n\nBrowser\n are available since version \n0.2\n of \nserps/core\n. \n\n\nCreate a browser\n\n\nA minimal browser only requires a http client to send request through:\n\n\nuse Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$browser = new Browser(new CurlClient());\n\n\n\n\nSetting user agent\n\n\nThe next step in configuring the browser is to specify what user agent we want to use:\n\n\nuse Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$userAgent = 'some user agent';\n\n$browser = new Browser(new CurlClient(), $userAgent);\n\n// Or set it latter:\n\n$browser->setAcceptLanguage('fr-CA');\n\n\n\n\n\nWhen setting a user agent you will prefer using a real user agent string.\nHere are a few user agent lists:\n\n\n\n\nfrom Chrome\n\n\nfrom Firefox\n\n\nfrom Opera\n\n\nfrom IE\n\n\n\n\nSetting the language\n\n\nThe browser is responsible for headers management. The accept-language header is one of the most important and thus\nyou should specify it when creating a new browser:\n\n\nuse Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$language = 'fr-FR';\n\n$browser = new Browser(new CurlClient(), $userAgent, $language);\n\n// Or set it latter:\n\n$browser->setUserAgent('other UA');\n\n\n\n\n\nIf you dont specify a language or if you set it to \nnull\n the default value \nen-US,en;q=0.8\n will be used.\n\n\nUsing a cookie jar\n\n\n\n\nWarning\n\n\nCookies usage is still at prototype stage and all http engines do not support cookies yet.\n\n\n\n\nAs real browser the browser class has the ability to use a cookie jar:\n\n\nuse Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$cookieJar = ....;\n\n$browser = new Browser(new CurlClient(), $userAgent, $language, $cookieJar);\n\n// Or set it latter:\n\n$browser->setCookieJar($otherCookieJar);\n\n// You can also remove it to disable cookies\n\n$browser->setCookieJar(null);\n\n\n\n\n\nBy default no cookie jar will be used and requests will be free of cookies.\n\n\nTo learn more on how to create cookie jar, please check \nthe cookie documentation\n\n\nUsing a proxy\n\n\nIt's possible to give a proxy for the browser. The browser will use this proxy for every requests.\n\n\nuse Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$proxy = ....;\n\n$browser = new Browser(new CurlClient(), $userAgent, $language, $cookieJar, $proxy);\n\n// Or set it latter:\n\n$browser->setProxy($otherProxy);\n\n// You can also remove it to disable proxy\n\n$browser->setProxy(null);\n\n\n\n\n\nBy default no proxy is used.\n\n\nTo learn more on how to create proxies, please check \nthe proxy documentation\n\n\nSetting default headers\n\n\nThe browser instance is able to add default headers for every requests sent to the browser.\n\n\nThat might be helpful, for instance, when you want to set a custom referrer to the http requests you send to a server.\n\n\n$browser->setDefaultHeader('Referer', 'my custom referrer');\n\n\n\n\nYou are also able to check if a default header is configured for the browser or to get the value for the header:\n\n\n$browser->hasDefaultHeader('Referer');      // = true\n$browser->getDefaultHeaderValue('Referer'); // = \"my custom referrer\"\n$browser->hasDefaultHeader('foo');          // = false \n$browser->getDefaultHeaderValue('foo');     // = null\n\n// note that hasDefaultHeader and getDefaultHeaderValue are case insensitive",
            "title": "Browser"
        },
        {
            "location": "/browser/#browser",
            "text": "Guide for browser instance management    In SERPS the  browser  is an element that helps to mimic the behavior of a browser.   Be aware that the name browser stand for the fact that this entity is capable of emitting http request as a real\nbrowser would do, taking care of cookies, proxies, language, etc... but  in any case  this class is able\nto render a html page or to evaluate css or javascript.  Browser  are available since version  0.2  of  serps/core .",
            "title": "Browser"
        },
        {
            "location": "/browser/#create-a-browser",
            "text": "A minimal browser only requires a http client to send request through:  use Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$browser = new Browser(new CurlClient());",
            "title": "Create a browser"
        },
        {
            "location": "/browser/#setting-user-agent",
            "text": "The next step in configuring the browser is to specify what user agent we want to use:  use Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$userAgent = 'some user agent';\n\n$browser = new Browser(new CurlClient(), $userAgent);\n\n// Or set it latter:\n\n$browser->setAcceptLanguage('fr-CA');  When setting a user agent you will prefer using a real user agent string.\nHere are a few user agent lists:   from Chrome  from Firefox  from Opera  from IE",
            "title": "Setting user agent"
        },
        {
            "location": "/browser/#setting-the-language",
            "text": "The browser is responsible for headers management. The accept-language header is one of the most important and thus\nyou should specify it when creating a new browser:  use Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$language = 'fr-FR';\n\n$browser = new Browser(new CurlClient(), $userAgent, $language);\n\n// Or set it latter:\n\n$browser->setUserAgent('other UA');  If you dont specify a language or if you set it to  null  the default value  en-US,en;q=0.8  will be used.",
            "title": "Setting the language"
        },
        {
            "location": "/browser/#using-a-cookie-jar",
            "text": "Warning  Cookies usage is still at prototype stage and all http engines do not support cookies yet.   As real browser the browser class has the ability to use a cookie jar:  use Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$cookieJar = ....;\n\n$browser = new Browser(new CurlClient(), $userAgent, $language, $cookieJar);\n\n// Or set it latter:\n\n$browser->setCookieJar($otherCookieJar);\n\n// You can also remove it to disable cookies\n\n$browser->setCookieJar(null);  By default no cookie jar will be used and requests will be free of cookies.  To learn more on how to create cookie jar, please check  the cookie documentation",
            "title": "Using a cookie jar"
        },
        {
            "location": "/browser/#using-a-proxy",
            "text": "It's possible to give a proxy for the browser. The browser will use this proxy for every requests.  use Serps\\Core\\Browser\\Browser;\nuse Serps\\HttpClient\\CurlClient;\n\n$proxy = ....;\n\n$browser = new Browser(new CurlClient(), $userAgent, $language, $cookieJar, $proxy);\n\n// Or set it latter:\n\n$browser->setProxy($otherProxy);\n\n// You can also remove it to disable proxy\n\n$browser->setProxy(null);  By default no proxy is used.  To learn more on how to create proxies, please check  the proxy documentation",
            "title": "Using a proxy"
        },
        {
            "location": "/browser/#setting-default-headers",
            "text": "The browser instance is able to add default headers for every requests sent to the browser.  That might be helpful, for instance, when you want to set a custom referrer to the http requests you send to a server.  $browser->setDefaultHeader('Referer', 'my custom referrer');  You are also able to check if a default header is configured for the browser or to get the value for the header:  $browser->hasDefaultHeader('Referer');      // = true\n$browser->getDefaultHeaderValue('Referer'); // = \"my custom referrer\"\n$browser->hasDefaultHeader('foo');          // = false \n$browser->getDefaultHeaderValue('foo');     // = null\n\n// note that hasDefaultHeader and getDefaultHeaderValue are case insensitive",
            "title": "Setting default headers"
        },
        {
            "location": "/cookies/",
            "text": "Cookies\n\n\nGuide for cookie and cookiejar manipulation \n\n\n\n\nSERPS offers convenient tools that emulate a cookiejar and allow to persist cookies across many requests.\n\n\nThe following examples introduce the work with cookies\n\n\n\n\nWarning\n\n\nCookies usage is still at prototype stage and all http engines do not support cookies yet.\n\n\n\n\nCreate a cookie\n\n\nParameters for creating a cookie:\n\n\n\n\nname\n: the name of a cookie.\n\n\nvalue\n: the value of a cookie.\n\n\nflags\n: cookie flags. Available flags are:\n\n\npath\n\n\ndomain\n\n\nexpires\n\n\ndiscard\n\n\nsecure\n\n\n\n\n\n\n\n\nuse Serps\\Core\\Cookie\\Cookie;\n\n$cookie = new Cookie('baz', 'bar', [\n    'domain' => 'foo.bar',\n    'path' => '/',\n    'expires' => time() + 1000,\n]);\n\n\n\n\nPopulate a Cookie Jar\n\n\nuse Serps\\Core\\Cookie\\ArrayCookieJar;\n\n$cookieJar = new ArrayCookieJar();\n\n// Add the cookie 'foo' with value 'bar' for the domain 'foo.bar'\n$cookie = new Cookie('foo', 'bar', ['domain' => 'foo.bar']);\n$cookieJar->set($cookie);\n\n// Add the cookie 'baz' with value 'bar' for the domain 'foo.bar'\n$cookie = new Cookie('baz', 'bar', ['domain' => 'foo.bar']);\n$cookieJar->set($cookie);\n\n\n\n\nRetrieving cookies\n\n\nThe \nall\n method is responsible for getting cookies matching some filters\n\n\nMethod parameters:\n\n\n\n\ndomain\n: filters the cookies matching the given domain. Pass null to match all domains.\n\n\npath\n: filters the cookies matching the given path. Pass null to match all paths.\n\n\nname\n: filters the cookies matching the given name. Pass null to match all names.\n\n\nskipDiscardable\n: Set to TRUE to skip cookies with the Discard attribute. Default FALSE.\n\n\nskipExpired\n: Set to FALSE to include expired. Default TRUE.\n\n\n\n\n// Retrieves all cookies\n$cookies = $cookieJar->all();\n\n// Retrieves all cookies matching the domain \"foo.bar\"\n$cookies = $cookieJar->all(\"foo.bar\");\n\n\n// Retrieves the cookie named \"foo\" for the domain \"foo.bar\", including expired cookies\n$cookies = $cookieJar->all(\"foo.bar\", \"/\", \"foo\", false, false);\n\n\n\n\nRetrieve cookies for a request\n\n\nIt's possible to automatically retrieve cookies that match a given PSR-7 request:\n\n\n// retrieves all cookies matching the request\n$cookies = $cookieJar->getMatchingCookies($request);\n\n\n\n\nRemove cookies\n\n\n// Remove all cookies\n$cookies = $cookieJar->remove();\n\n// Remove all cookies matching the domain \"foo.bar\"\n$cookies = $cookieJar->remove(\"foo.bar\");\n\n// Remove the cookie named \"foo\" for the domain \"foo.bar\"\n$cookies = $cookieJar->remove(\"foo.bar\", \"/\", \"foo\");\n\n\n\n\nRemove temporary cookies\n\n\n// Remove all temporary cookies\n$cookies = $cookieJar->removeTemporary();\n\n\n\n\nRemove expired cookies\n\n\n// Remove all cookies that are expired\n$cookies = $cookieJar->removeExpired();\n\n\n\n\nSerialize cookies\n\n\nCookies can be exported in a serializable format, thus it's possible to save the state and to\nuse it latter.\n\n\n// serialize cookies using json\n$serializableCookieJar = $cookieJar->export();\n$serializedCookieJar = json_encode($serializableCookieJar);\n\n// Unserialize cookies in an other cookie jar\n$otherCookieJar->import(json_decode($serializedCookieJar, true));",
            "title": "Cookies"
        },
        {
            "location": "/cookies/#cookies",
            "text": "Guide for cookie and cookiejar manipulation    SERPS offers convenient tools that emulate a cookiejar and allow to persist cookies across many requests.  The following examples introduce the work with cookies   Warning  Cookies usage is still at prototype stage and all http engines do not support cookies yet.",
            "title": "Cookies"
        },
        {
            "location": "/cookies/#create-a-cookie",
            "text": "Parameters for creating a cookie:   name : the name of a cookie.  value : the value of a cookie.  flags : cookie flags. Available flags are:  path  domain  expires  discard  secure     use Serps\\Core\\Cookie\\Cookie;\n\n$cookie = new Cookie('baz', 'bar', [\n    'domain' => 'foo.bar',\n    'path' => '/',\n    'expires' => time() + 1000,\n]);",
            "title": "Create a cookie"
        },
        {
            "location": "/cookies/#populate-a-cookie-jar",
            "text": "use Serps\\Core\\Cookie\\ArrayCookieJar;\n\n$cookieJar = new ArrayCookieJar();\n\n// Add the cookie 'foo' with value 'bar' for the domain 'foo.bar'\n$cookie = new Cookie('foo', 'bar', ['domain' => 'foo.bar']);\n$cookieJar->set($cookie);\n\n// Add the cookie 'baz' with value 'bar' for the domain 'foo.bar'\n$cookie = new Cookie('baz', 'bar', ['domain' => 'foo.bar']);\n$cookieJar->set($cookie);",
            "title": "Populate a Cookie Jar"
        },
        {
            "location": "/cookies/#retrieving-cookies",
            "text": "The  all  method is responsible for getting cookies matching some filters  Method parameters:   domain : filters the cookies matching the given domain. Pass null to match all domains.  path : filters the cookies matching the given path. Pass null to match all paths.  name : filters the cookies matching the given name. Pass null to match all names.  skipDiscardable : Set to TRUE to skip cookies with the Discard attribute. Default FALSE.  skipExpired : Set to FALSE to include expired. Default TRUE.   // Retrieves all cookies\n$cookies = $cookieJar->all();\n\n// Retrieves all cookies matching the domain \"foo.bar\"\n$cookies = $cookieJar->all(\"foo.bar\");\n\n\n// Retrieves the cookie named \"foo\" for the domain \"foo.bar\", including expired cookies\n$cookies = $cookieJar->all(\"foo.bar\", \"/\", \"foo\", false, false);  Retrieve cookies for a request  It's possible to automatically retrieve cookies that match a given PSR-7 request:  // retrieves all cookies matching the request\n$cookies = $cookieJar->getMatchingCookies($request);",
            "title": "Retrieving cookies"
        },
        {
            "location": "/cookies/#remove-cookies",
            "text": "// Remove all cookies\n$cookies = $cookieJar->remove();\n\n// Remove all cookies matching the domain \"foo.bar\"\n$cookies = $cookieJar->remove(\"foo.bar\");\n\n// Remove the cookie named \"foo\" for the domain \"foo.bar\"\n$cookies = $cookieJar->remove(\"foo.bar\", \"/\", \"foo\");  Remove temporary cookies  // Remove all temporary cookies\n$cookies = $cookieJar->removeTemporary();  Remove expired cookies  // Remove all cookies that are expired\n$cookies = $cookieJar->removeExpired();",
            "title": "Remove cookies"
        },
        {
            "location": "/cookies/#serialize-cookies",
            "text": "Cookies can be exported in a serializable format, thus it's possible to save the state and to\nuse it latter.  // serialize cookies using json\n$serializableCookieJar = $cookieJar->export();\n$serializedCookieJar = json_encode($serializableCookieJar);\n\n// Unserialize cookies in an other cookie jar\n$otherCookieJar->import(json_decode($serializedCookieJar, true));",
            "title": "Serialize cookies"
        },
        {
            "location": "/proxy/",
            "text": "Proxy\n\n\nGuide to proxy management in SERPS\n\n\n\n\nProvided you have a working proxy, this short guide will show you to use it with SERPS in a standardized way. \n\n\nCreate a proxy\n\n\nProxy creation is possible in two ways. You can either build it from a \nsimple proxy string\n, or with \nproxy parts\n\n\nCreate a proxy from a string\n\n\nAssuming we have the proxy as a string, for instance with \n196.168.192.168:8080\n, you can use this string to \ncreate the proxy:\n\n\n use Serps\\Core\\Http\\Proxy;\n\n $proxy = Proxy::createFromString('196.168.192.168:8080');\n\n\n\n\nBy default the proxy will be a \nHTTP\n proxy but serps proxy also accepts \nHTTPS\n,\n \nSOCKS4\n and \nSOCKS5\n proxies, see with examples:\n\n\n use Serps\\Core\\Http\\Proxy;\n\n $httpProxy = Proxy::createFromString('http://196.168.192.168:8080');\n $httpsProxy = Proxy::createFromString('https://196.168.192.168:8080');\n $socks4Proxy = Proxy::createFromString('socks4://196.168.192.168:8080');\n $socks5Proxy = Proxy::createFromString('socks5://196.168.192.168:8080');\n\n\n\n\nYou can also add \nauthentication\n details (by default no authentication is set). You can do it by using the form\n\nauthentication\n@\nhost\n:\n\n\n    use Serps\\Core\\Http\\Proxy;\n\n    $proxy = Proxy::createFromString('https://user:password@196.168.192.168:8080');\n\n\n\n\nCreate a proxy from parts\n\n\nNow let's consider that you have some proxy parts (ip, port...) that are not put together as a string, you can use\nthem directly with the proxy constructor to create a new proxy:\n\n\n    use Serps\\Core\\Http\\Proxy;\n\n    $ip   = '192.168.192.168';\n    $port = 8080;\n\n    $proxy = new Proxy($ip, $port);\n\n\n\n\nBy default authentication is disabled and the proxy is an \nHTTP\n proxy but you can provide these details:\n\n\n    use Serps\\Core\\Http\\Proxy;\n\n     $type = 'HTTP';\n     $ip   = '192.168.192.168';\n     $port = 8080;\n     $user = 'user';\n     $pass = 'password';\n\n    $proxy = new Proxy($ip, $port, $user, $pass, $type);\n\n\n\n\nWhat to do with proxies\n\n\nThese proxies are aimed to be used by \nBrowser\n instances. Find example on how to use them on the \n\nbrowser documentation",
            "title": "Proxies"
        },
        {
            "location": "/proxy/#proxy",
            "text": "Guide to proxy management in SERPS   Provided you have a working proxy, this short guide will show you to use it with SERPS in a standardized way.",
            "title": "Proxy"
        },
        {
            "location": "/proxy/#create-a-proxy",
            "text": "Proxy creation is possible in two ways. You can either build it from a  simple proxy string , or with  proxy parts  Create a proxy from a string  Assuming we have the proxy as a string, for instance with  196.168.192.168:8080 , you can use this string to \ncreate the proxy:   use Serps\\Core\\Http\\Proxy;\n\n $proxy = Proxy::createFromString('196.168.192.168:8080');  By default the proxy will be a  HTTP  proxy but serps proxy also accepts  HTTPS ,\n  SOCKS4  and  SOCKS5  proxies, see with examples:   use Serps\\Core\\Http\\Proxy;\n\n $httpProxy = Proxy::createFromString('http://196.168.192.168:8080');\n $httpsProxy = Proxy::createFromString('https://196.168.192.168:8080');\n $socks4Proxy = Proxy::createFromString('socks4://196.168.192.168:8080');\n $socks5Proxy = Proxy::createFromString('socks5://196.168.192.168:8080');  You can also add  authentication  details (by default no authentication is set). You can do it by using the form authentication @ host :      use Serps\\Core\\Http\\Proxy;\n\n    $proxy = Proxy::createFromString('https://user:password@196.168.192.168:8080');  Create a proxy from parts  Now let's consider that you have some proxy parts (ip, port...) that are not put together as a string, you can use\nthem directly with the proxy constructor to create a new proxy:      use Serps\\Core\\Http\\Proxy;\n\n    $ip   = '192.168.192.168';\n    $port = 8080;\n\n    $proxy = new Proxy($ip, $port);  By default authentication is disabled and the proxy is an  HTTP  proxy but you can provide these details:      use Serps\\Core\\Http\\Proxy;\n\n     $type = 'HTTP';\n     $ip   = '192.168.192.168';\n     $port = 8080;\n     $user = 'user';\n     $pass = 'password';\n\n    $proxy = new Proxy($ip, $port, $user, $pass, $type);",
            "title": "Create a proxy"
        },
        {
            "location": "/proxy/#what-to-do-with-proxies",
            "text": "These proxies are aimed to be used by  Browser  instances. Find example on how to use them on the  browser documentation",
            "title": "What to do with proxies"
        },
        {
            "location": "/search-engine/google/",
            "text": "Google Client\n\n\n\n\nEverything about the google client\n\n\n\n\n\n\nInstallation and overview\n\n\nConfigure the google client\n\n\nCreate urls\n\n\nParse a google page\n\n\nHandle errors\n\n\n\n\n\n\nInstallation\n\n\nThe google client is available with the package \n\nserps/search-engine-google\n: \n\n\n$ composer require 'serps/search-engine-google'\n\n\nIn addition you will require to install either zend-diactoros or guzzle/psr7 to provide a psr7 implementation\n\n\n$ composer require 'zendframework/zend-diactoros'\n\n\nor \n\n\n$ composer require 'guzzlehttp/psr7'\n\n\n\n\nImportant note about google updates\n\n\nWe don't know when google dom updates, but when it does, we will place as many efforts as possible\nto get the client updated.\n\n\nTo make sure you are always up to date we advice you to \n\nwatch the repository on github\n.\nNot only you will be notified when a release is published, but you will also know when a bug is detected and \nreported on the issue tracker.\n\n\n\n\nOverview\n\n\nThe google client needs a browser to be constructed and an url to be parsed.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Core\\Browser\\Browser;\n\n    $userAgent = \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\";\n    $browserLanguage = \"fr-FR\";\n\n    $browser = new Browser(new CurlClient(), $userAgent, $browserLanguage);\n\n    // Create a google client using the browser we configured\n    $googleClient = new GoogleClient($browser);\n\n    // Create the url that will be parsed\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        // Analyse the results\n    }\n\n\n\n\n\n\nDisclaimer\n\n\n\n\nUsing our Services does not give you ownership of any intellectual property rights in \nour Services or the content you access. \nYou may not use content from our Services unless you obtain permission from its owner or \nare otherwise permitted by law.\n\n\nExtract from \nGoogle terms of services\n\n\n\n\nWhen using this software must respect terms of services of third parties like Google.\nSerps authors and contributors cannot be hold as liable for the use you make of this software. \n\n\n\n\nNext steps: \n\n\n\n\nConfigure the google client\n\n\nCreate urls\n\n\nParse a google page\n\n\nHandle errors",
            "title": "Google"
        },
        {
            "location": "/search-engine/google/#google-client",
            "text": "Everything about the google client    Installation and overview  Configure the google client  Create urls  Parse a google page  Handle errors",
            "title": "Google Client"
        },
        {
            "location": "/search-engine/google/#installation",
            "text": "The google client is available with the package  serps/search-engine-google :   $ composer require 'serps/search-engine-google'  In addition you will require to install either zend-diactoros or guzzle/psr7 to provide a psr7 implementation  $ composer require 'zendframework/zend-diactoros'  or   $ composer require 'guzzlehttp/psr7'   Important note about google updates  We don't know when google dom updates, but when it does, we will place as many efforts as possible\nto get the client updated.  To make sure you are always up to date we advice you to  watch the repository on github .\nNot only you will be notified when a release is published, but you will also know when a bug is detected and \nreported on the issue tracker.",
            "title": "Installation"
        },
        {
            "location": "/search-engine/google/#overview",
            "text": "The google client needs a browser to be constructed and an url to be parsed.      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Core\\Browser\\Browser;\n\n    $userAgent = \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\";\n    $browserLanguage = \"fr-FR\";\n\n    $browser = new Browser(new CurlClient(), $userAgent, $browserLanguage);\n\n    // Create a google client using the browser we configured\n    $googleClient = new GoogleClient($browser);\n\n    // Create the url that will be parsed\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        // Analyse the results\n    }",
            "title": "Overview"
        },
        {
            "location": "/search-engine/google/#disclaimer",
            "text": "Using our Services does not give you ownership of any intellectual property rights in \nour Services or the content you access. \nYou may not use content from our Services unless you obtain permission from its owner or \nare otherwise permitted by law.  Extract from  Google terms of services   When using this software must respect terms of services of third parties like Google.\nSerps authors and contributors cannot be hold as liable for the use you make of this software.    Next steps:    Configure the google client  Create urls  Parse a google page  Handle errors",
            "title": "Disclaimer"
        },
        {
            "location": "/http-client/curl/",
            "text": "Curl HTTP Client\n\n\nCurl adapter for a simple scraping implementation\n\n\n\n\nCurl Adapter will allow to use the built in php CURL extension. This adapter \nfully supports proxies and cookies\n\n\nInstallation\n\n\nThe client is available with the package \n\nserps/http-client-curl\n: \n\n\n$ composer require 'serps/http-client-curl'\n\n\nAdditional requirement\n\n\nThis http client requires you to \ninstall the Curl php extension\n\n\nWarning !\n It appears that before version 7.48 of curl \na bug\n affects \nthe cookie management. \nMake sure that the version of curl on your system is >=7.48 (\ncurl --version\n to check).\n\n\nUsage\n\n\nuse Serps\\HttpClient\\PhantomJsClient;\n\n$client = new CurlClient();",
            "title": "CURL"
        },
        {
            "location": "/http-client/curl/#curl-http-client",
            "text": "Curl adapter for a simple scraping implementation   Curl Adapter will allow to use the built in php CURL extension. This adapter  fully supports proxies and cookies",
            "title": "Curl HTTP Client"
        },
        {
            "location": "/http-client/curl/#installation",
            "text": "The client is available with the package  serps/http-client-curl :   $ composer require 'serps/http-client-curl'  Additional requirement  This http client requires you to  install the Curl php extension  Warning !  It appears that before version 7.48 of curl  a bug  affects \nthe cookie management. \nMake sure that the version of curl on your system is >=7.48 ( curl --version  to check).",
            "title": "Installation"
        },
        {
            "location": "/http-client/curl/#usage",
            "text": "use Serps\\HttpClient\\PhantomJsClient;\n\n$client = new CurlClient();",
            "title": "Usage"
        },
        {
            "location": "/http-client/phantomJS/",
            "text": "PhantomJS HTTP Client\n\n\n\n\nPhantomJS\n is a webkit implementation that helps to simulate the real browser.\n\n\n\n\nBy using this client you will execute the inner javascript code and make the DOM as real as in the true browser,\nthat can be required for some search engines to work properly.\n\n\n\n\nNotice about cookies\n\n\nAt the current state phantomJS adapter does not support internal cookieJar usage.\n\n\n\n\nInstallation\n\n\nThe client is available with the package \n\nserps/http-client-phantomjs\n: \n\n\n$ composer require 'serps/http-client-phantomjs'\n\n\nAdditional requirement\n\n\nPhantomJS\n binaries have to be installed\n to use the client. The process for installing\nit depends on your environment, you will find further guides on the internet. \n\n\nThe following PhantomJs version were tested with the library:\n\n\n\n\n1.9.7\n\n\n1.9.8\n\n\n2.0.0\n\n\n2.1.0\n\n\n\n\n\n\nNote\n\n\nThe package \njakoch/phantomjs-installer\n \ncan help you to manage phantomJS as a dependency of your project.\n\n\n\n\nUsage\n\n\nuse Serps\\HttpClient\\PhantomJsClient;\n\n// The constructor accepts 1 optional parameter that is the path to the phantomjs binaries (default to 'phantomjs')\n$client = new PhantomJsClient();\n\n\n\n\nCustom headers\n\n\nIt's possible to set custom headers that will be sent with all requests sent with the client\n\n\nuse Serps\\HttpClient\\PhantomJsClient;\n\n// The constructor accepts 1 optional parameter that is the path to the phantomjs binaries (default to 'phantomjs')\n$client = new PhantomJsClient();\n$client->setCustomHeader('referer', 'https://www.google.com'); \n// All request will the header 'referer: https://www.google.com' added",
            "title": "PhantomJS"
        },
        {
            "location": "/http-client/phantomJS/#phantomjs-http-client",
            "text": "PhantomJS  is a webkit implementation that helps to simulate the real browser.   By using this client you will execute the inner javascript code and make the DOM as real as in the true browser,\nthat can be required for some search engines to work properly.   Notice about cookies  At the current state phantomJS adapter does not support internal cookieJar usage.",
            "title": "PhantomJS HTTP Client"
        },
        {
            "location": "/http-client/phantomJS/#installation",
            "text": "The client is available with the package  serps/http-client-phantomjs :   $ composer require 'serps/http-client-phantomjs'  Additional requirement  PhantomJS  binaries have to be installed  to use the client. The process for installing\nit depends on your environment, you will find further guides on the internet.   The following PhantomJs version were tested with the library:   1.9.7  1.9.8  2.0.0  2.1.0    Note  The package  jakoch/phantomjs-installer  \ncan help you to manage phantomJS as a dependency of your project.",
            "title": "Installation"
        },
        {
            "location": "/http-client/phantomJS/#usage",
            "text": "use Serps\\HttpClient\\PhantomJsClient;\n\n// The constructor accepts 1 optional parameter that is the path to the phantomjs binaries (default to 'phantomjs')\n$client = new PhantomJsClient();  Custom headers  It's possible to set custom headers that will be sent with all requests sent with the client  use Serps\\HttpClient\\PhantomJsClient;\n\n// The constructor accepts 1 optional parameter that is the path to the phantomjs binaries (default to 'phantomjs')\n$client = new PhantomJsClient();\n$client->setCustomHeader('referer', 'https://www.google.com'); \n// All request will the header 'referer: https://www.google.com' added",
            "title": "Usage"
        },
        {
            "location": "/http-client/spidyJS/",
            "text": "SpidyJS HTTP Client\n\n\nSpidy\n is a browser built with javascript. \n\n\n\n\nThis adapter allows you to query search engines with spidyJS, it is a javascript headless browser. \n\n\n\n\nWarning\n\n\nThis adapter is still a prototype. Use it with care.\n\n\n\n\nInstallation\n\n\nThe client is available with the package \n\nserps/http-client-spidyjs\n: \n\n\n$ composer require 'serps/http-client-spidyjs'\n\n\nAdditional requirement\n\n\nYou will also need nodejs and npm to install spidy.\n\n\n$ npm install -g spidy@2\n\n\n\n\nIf you use a nodejs version that is before 4.0, you will need to install spidy version 1 instead:\n\n\n$ npm install -g spidy@1\n\n\n\n\nUsage\n\n\nuse Serps\\HttpClient\\SpidyJsClient;\n\n\n// The constructor accepts 1 optional parameter that is the path to the spidyjs binaries (default to 'spidyjs')\n$client = new SpidyJsClient();",
            "title": "SpidyJS"
        },
        {
            "location": "/http-client/spidyJS/#spidyjs-http-client",
            "text": "Spidy  is a browser built with javascript.    This adapter allows you to query search engines with spidyJS, it is a javascript headless browser.    Warning  This adapter is still a prototype. Use it with care.",
            "title": "SpidyJS HTTP Client"
        },
        {
            "location": "/http-client/spidyJS/#installation",
            "text": "The client is available with the package  serps/http-client-spidyjs :   $ composer require 'serps/http-client-spidyjs'  Additional requirement  You will also need nodejs and npm to install spidy.  $ npm install -g spidy@2  If you use a nodejs version that is before 4.0, you will need to install spidy version 1 instead:  $ npm install -g spidy@1",
            "title": "Installation"
        },
        {
            "location": "/http-client/spidyJS/#usage",
            "text": "use Serps\\HttpClient\\SpidyJsClient;\n\n\n// The constructor accepts 1 optional parameter that is the path to the spidyjs binaries (default to 'spidyjs')\n$client = new SpidyJsClient();",
            "title": "Usage"
        },
        {
            "location": "/about/packages/",
            "text": "Packages\n\n\nList of packages that are part of this project\n\n\n\n\nCore\n\n\nThis is the core of SERPS. It contains the common tools that are used by search engine and http client implementations\n\n\n Github\n\n\n$ composer require serps/serps\n\n\n\n\n\n\n\n\n\n\nSearch engines\n\n\nGoogle\n\n\nThe google client implementation\n\n\n Github\n\n\n$ composer require serps/search-engine-google\n\n\n\n\n\n\n\n\n\n\nHttp clients\n\n\nCurl\n\n\nCurl Http client\n\n\n Doc\n\n\n Github\n\n\n$ composer require serps/http-client-curl\n\n\n\n\n\n\n\n\nPhantomJS\n\n\nPhantomJS Http client\n\n\n Doc\n\n\n Github\n\n\n$ composer require serps/http-client-phantomjs\n\n\n\n\n\n\n\n\n\n\nSpidyJS\n\n\nnodejs browser built specially for SERPS\n\n\n Github\n\n\n$ npm install spidyjs\n\n\n\nmaster (node >= 4):\n\n\n1.x (node < 4):\n\n\n\nWebsite homepage\n\n\nSimply the homepage at https://serp-spider.github.io/\n\n\n Github\n\n\nDocumentation\n\n\nThe package that contains this documentation at http://serp-spider.github.io/documentation\n\n\n Github\n\n\nStatus monitor\n\n\nCli application that helps to monitor search engine changes\n\n\n Github",
            "title": "Packages"
        },
        {
            "location": "/about/packages/#packages",
            "text": "List of packages that are part of this project",
            "title": "Packages"
        },
        {
            "location": "/about/packages/#core",
            "text": "This is the core of SERPS. It contains the common tools that are used by search engine and http client implementations   Github  $ composer require serps/serps",
            "title": "Core"
        },
        {
            "location": "/about/packages/#search-engines",
            "text": "Google  The google client implementation   Github  $ composer require serps/search-engine-google",
            "title": "Search engines"
        },
        {
            "location": "/about/packages/#http-clients",
            "text": "Curl  Curl Http client   Doc   Github  $ composer require serps/http-client-curl     PhantomJS  PhantomJS Http client   Doc   Github  $ composer require serps/http-client-phantomjs",
            "title": "Http clients"
        },
        {
            "location": "/about/packages/#spidyjs",
            "text": "nodejs browser built specially for SERPS   Github  $ npm install spidyjs  \nmaster (node >= 4): \n1.x (node < 4):",
            "title": "SpidyJS"
        },
        {
            "location": "/about/packages/#website-homepage",
            "text": "Simply the homepage at https://serp-spider.github.io/   Github",
            "title": "Website homepage"
        },
        {
            "location": "/about/packages/#documentation",
            "text": "The package that contains this documentation at http://serp-spider.github.io/documentation   Github",
            "title": "Documentation"
        },
        {
            "location": "/about/packages/#status-monitor",
            "text": "Cli application that helps to monitor search engine changes   Github",
            "title": "Status monitor"
        },
        {
            "location": "/about/versions/",
            "text": "Versions\n\n\n\n\nMigration to 0.2.0",
            "title": "Versions"
        },
        {
            "location": "/about/versions/#versions",
            "text": "Migration to 0.2.0",
            "title": "Versions"
        },
        {
            "location": "/search-engine/google/parse-page/",
            "text": "Parse a Google Page\n\n\n\n\nThe necessary documentation about parsing a google page\n\n\n\n\nBack to the \ngeneral google documentation\n.\n\n\n\n\nParsing a page consists in the structured extraction of parts of the page. The end result is the ability to \nmake the distinction between these different parts and to gather details on them to show them in another fashion.\n\n\n\n\nImportant notice about google update\n\n\nThe following examples can change at any time. \n\n\nAs soon as google changes its page structure, you may need to update the library.\nYou can \nwatch the repository on github\n\nto be warned of new releases as they come.\n\n\n\n\n\n\nA google SERP can contain different type of result.\nFirstly they are divided in three distinct regions: \nnatural\n (organic), \npaid\n (adwords) and \ngraph results\n and each of them\nhas its own results types. Graph result are \nnot supported\n by the library.\n\n\nThere is a great diversity of results and the library gives you the api to work with them, here we document\nhow you will work with. \n\n\nNatural Results\n\n\nNatural results (aka organic results) are main results of the page.\n\n\nEach natural result has a position and some available data. You can access them the following way (see the foreach loop):\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleClient = new GoogleClient($httpClient);\n\n    $googleUrl = new GoogleUrl();\n    $google->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        // Here we iterate over the result list\n        // Each result will have different data based on its type\n    }\n\n\n\n\nEach of the result from the loop will have the following methods available:\n\n\n\n\ngetTypes()\n: the types of the result\n\n\nis($type)\n: check if the result is of the given type\n\n\ngetDataValue($type)\n: Get the given data from the result. Everything accessible with \ngetDataValue\n\nis also accessible with a property, e.g the two examples do the same thing: \n$result->getDataValue('url')\n and \n$result->url\n\n\ngetData()\n: Get the all the data of the result\n\n\ngetOnPagePosition()\n: Get the position of the result on the page (starting at 1)\n\n\ngetRealPosition()\n: Get the global position of the result (starting at 1), that means it is aware of the pagination. \nBe aware\n that in some circumstances this number can be wrong because google might show more results on the previous pages.\n\n\n\n\nThe difference between each result type is the list of data available with \ngetDataValue($type)\n and \ngetData()\n.\nSee bellow for all available data per result type.\n\n\nNatural Result Types\n\n\nResult types\n can be accessed through the class \nNaturalResultType\n,\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    if($result->is(NaturalResultType::CLASSICAL)){\n        // Do stuff\n    }\n\n    // You can also check many types at once\n    // Here we check if the result is classical or image group\n\n    if($result->is(NaturalResultType::CLASSICAL, NaturalResultType::IMAGE_GROUP)){\n        // Do stuff\n    }\n\n\n\n\nFrom the \nresultSet\n you can also access all the results matching one of the given type:\n\n\n    // Get all the results that are either classical or image_group\n    $results = $results->getResultsByType(NaturalResultType::CLASSICAL, NaturalResultType::IMAGE_GROUP);\n\n\n\n\nClassical\n\n\nThese results are the common natural results that have always existed in google.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::CLASSICAL\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n [\nA\n]\n\n\nurl\n \nstring\n: the url targeted on clicking the title\n\n\ndestination\n \nstring\n [\nB\n]: either a url or a breadcrumb-like destination\n\n\ndescription\n \nstring\n [\nC\n]\n\n\nisAmp\n \nboolean\n true if the results is an \nAMP\n result\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL)){\n            $title = $result->title;\n            $url   = $result->url;\n        }\n    }\n\n\n\n\nClassical Large\n\n\nThis type is an extension of the \nclassical result\n, with sitelinks in addition.\n\n\n\n\nMobile version (since version 0.2): \n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::CLASSICAL_LARGE\n\n\nNaturalResultType::CLASSICAL\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n [\nA\n]\n\n\nurl\n \nstring\n: the url targeted on clicking the title\n\n\ndestination\n \nstring\n [\nB\n]: either a url or a breadcrumb-like destination\n\n\ndescription\n \nstring\n [\nC\n]\n\n\nsitelinks\n \narray\n:\n\n\ntitle\n \nstring\n [\nD\n]\n\n\nurl\n \nstring\n: the url targeted on clicking the sitelink title\n\n\ndescription\n \nstring\n [\nE\n]\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL_LARGE)){\n            $title = $result->title;\n            $url   = $result->url;\n            $sitelinks = $result->sitelinks;\n            foreach ($sitelinks as $sitelink) {\n                $sitelinkTitle = $sitelink->title;\n            }\n        }\n    }\n\n\n\n\nClassical Video\n\n\nThis type an extension of the \nclassical result\n, but it refers to a video result.\n\n\nThe video result can be illustrated with either a thumbnail or a large image.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::CLASSICAL_VIDEO\n\n\nNaturalResultType::CLASSICAL\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n [\nA\n]\n\n\nurl\n \nstring\n: the url targeted on clicking the title\n\n\ndestination\n \nstring\n [\nB\n]: either a url or a breadcrumb-like destination\n\n\ndescription\n \nstring\n [\nC\n]\n\n\nvideoLarge\n \nbool\n: true if the video is image is large (usually first result)\n\n\nvideoCover\n \nMedia Object\n: The video cover. Only if videoLarge is true\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL_VIDEO)){\n            $title = $result->title;\n            if($result->videoLarge){\n                // ...\n            }\n        }\n    }\n\n\n\n\nClassical Illustrated\n\n\nClassical results might have an additional \nCLASSICAL_ILLUSTRATED\n type when the results is \nillustrated with a thumbnail. Non large video results have this type as well.\n\n\nAvailable with\n\n\n\n\nNaturalResultType::CLASSICAL_ILLUSTRATED\n\n\n\n\nData\n\n\n\n\nthumb\n \nMedia Object\n: the thumbnail\n\n\n\n\nImage Group\n\n\nImages that appear as a group of results.\n\n\n\n\nMobile version (since version 0.2):\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::IMAGE_GROUP\n\n\n\n\nData\n\n\n\n\nimages\n \narray\n: the list of images that compose the image group, each image contains:\n\n\nsourceUrl\n \nstring\n: the url where the image was found\n\n\ntargetUrl\nstring\n: the url reached on clicking the image\n\n\nimage\n \nstring\n: the image data as specified by google (either an image url or a base64 encoded image)\n\n\n\n\n\n\nmoreUrl\n \nstring\n: The url corresponding to the google image search\n\n\nisCarousel\n \nboolean\n: True if images have the form of a carousel (since version 0.2)\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::IMAGE_GROUP)){\n            foreach($result->images as $image){\n                $sourceUrl = $image->sourceUrl;\n            }\n        }\n    }\n\n\n\n\nVideo Group\n\n\nThis type is present on mobile results and was added with version \n0.2\n. \n\n\nIt shows some videos (usualy 10) arranged in a carousel.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::VIDEO_GROUP\n\n\n\n\nData\n\n\n\n\nvideos\n \narray\n: the list of images that compose the image group, each image contains:\n\n\ntitle\n \nstring\n: Title of the video\n\n\nurl\nstring\n: the url reached on clicking the item\n\n\nimage\n \nMedia object\n: image of the video\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::VIDEO_GROUP)){\n            foreach($result->videos as $video){\n                $url = $video->url;\n            }\n        }\n    }\n\n\n\n\nMap\n\n\nA result illustrated by a map and that contains sub-results.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::MAP\n\n\n\n\nData\n\n\n\n\nlocalPack\n \narray\n: The sub results for the map:\n\n\ntitle\n \nstring\n \n[A]\n: Name of the place\n\n\nurl\nstring\n \n[B]\n: Website of the sub-result\n\n\nstreet\n \nstring\n \n[C]\n: The address of the sub-result\n\n\nstars\n \nstring\n \n[D]\n: The rating of the result as a number\n\n\nreview\n \nstring\n \n[E]\n: The review string as specified by google (e.g '1 review')\n\n\nphone\n \nstring\n \n[G]\n: The phone number\n\n\n\n\n\n\nmapUrl\n \nstring\n \n[F]\n: The url to access the map search\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::MAP)){\n            foreach($result->localPack as $place){\n                $website = $place->website;\n            }\n        }\n    }\n\n\n\n\nAnswer Box\n\n\nBlock that answers a question asked by the keywords.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::ANSWER_BOX\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n [\nA\n]\n\n\nurl\n \nstring\n: the url targeted on clicking the title\n\n\ndestination\n \nstring\n [\nB\n]: either a url or a breadcrumb-like destination\n\n\ndescription\n \nstring\n [\nC\n]\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::ANSWER_BOX)){\n            $title = $result->title;\n            $url   = $result->url;\n        }\n    }\n\n\n\n\nKnowledge\n\n\nSince version 0.2.1\n\n\nKnowledge boxes that appear among mobile results. \n\n\nBe aware that knowledge results are only included if they are present among the result list. \nThat means that on non-mobile results knowledge results are not available because they are placed on the right \nof natural results.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::KNOWLEDGE\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n [\nA\n]\n\n\nshortDescription\n \nstring\n [\nB\n] nature of the element (character, \n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::KNOWLEDGE)){\n            $title = $result->title;\n            $description   = $result->shortDescription;\n        }\n    }\n\n\n\n\nPeople Also Ask\n\n\nSince version 0.2.3\n\n\nList of questions that people also ask\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::PEOPLE_ALSO_ASK\n\n\n\n\nData\n\n\n\n\nquestions\n \narray\n\n\nquestion\n \nstring\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::PEOPLE_ALSO_ASK)){\n            $questions = $result->questions;\n\n            foreach ($questions as $question) {\n                $questionText = $question->question;\n            }\n        }\n    }\n\n\n\n\nTweet Carousel\n\n\nRecent tweet list from an user matching the search keywords.\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::TWEETS_CAROUSEL\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n \n[A]\n\n\nurl\n \nstring\n: The url reach when clicking the title\n\n\nuser\nstring\n: The author of the tweets\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::TWEETS_CAROUSEL)){\n            $user = $result->user;\n        }\n    }\n\n\n\n\nIn the News\n\n\nRecent news results.\n\n\n\n\nThese results do not exists anymore\n\n\nIn early 2017 Google deleted in the news results, they were replaced by \"top stories\" results.\nThese results are now deprecated and might be deleted from serps in future releases.\n\n\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::IN_THE_NEWS\n\n\n\n\nData\n\n\n\n\nnews\n \narray\n\n\ntitle\n \nstring\n \n[A]\n\n\ndescription\n \nstring\n \n[B]\n\n\nurl\nstring\n: The url reached when clicking the title\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::IN_THE_NEWS)){\n            foreach($result->news as $news){\n                $newsTitle = $title;\n                $newsUrl = $url;\n            }\n        }\n    }\n\n\n\n\nTop Stories\n\n\nList of recent popular news.\n\n\n\n\nImplemented in version \n0.1.4\n as a successor for \"in the news\"\n\n\nComposed top stories for mobile were implemented with version \n0.2.2\n \n\n\n\n\nTop stories might be present in 3 distinctive formats: \ncarousel\n, \nvertical\n, \ncomposed\n. \n\n\nCarousel\n\n\n\n\nVertical\n\n\n\n\nComposed\n (mobile)\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::TOP_STORIES\n\n\nNaturalResultType::COMPOSED_TOP_STORIES\n\n\n\n\nNote: all top stories have the type \nNaturalResultType::TOP_STORIES\n. In addition of what composed top stories\nalso have \nNaturalResultType::COMPOSED_TOP_STORIES\n.\n\n\nData\n\n\n\n\nisCarousel\n \nboolean\n: true when has a carousel\n\n\nisVertical\n \nboolean\n: true when has vertical items\n\n\nnews\n \narray\n\n\ntitle\n \nstring\n \n[A]\n\n\nurl\nstring\n: The url reached when clicking the title\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::TOP_STORIES)){\n            foreach($result->news as $news){\n                $newsTitle = $title;\n                $newsUrl = $url;\n            }\n        }\n    }\n\n\n\n\nAbout composed top stories\n\n\nComposed top stories are mixing both of vertical and carousel news that appear on mobiles. \nThe composed results will have variables \nisCarousel\n \nand\n \nisVertical\n set to true.\n\n\nWhen iterating over news you can check if the news is a carousel or a vertical result:\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    foreach($result->news as $news){\n        if ($news->is(NaturalResultType::TOP_STORIES_NEWS_CAROUSEL) {\n            // carousel\n        } elseif ($news->is(NaturalResultType::TOP_STORIES_NEWS_VERTICAL) {\n            // vertical\n        }\n    }\n\n\n\n\nYou can also distinctly get one of the result types:\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $carouselResults = $result->news->getResultsByType(NaturalResultType::TOP_STORIES_NEWS_CAROUSEL);\n\n\n\n\nFlights\n\n\nFlight sample from google flights\n\n\n\n\nAvailable with\n\n\n\n\nNaturalResultType::FLIGHTS\n\n\n\n\nData\n\n\nNo data is parsed from flight results. There is no plan to implement it because it's complex and not very useful.\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::FLIGHTS)){\n            // Got a flight result\n        }\n    }\n\n\n\n\nAdwords Results\n\n\nThe google client offers an Adwords parser.\n\n\n\n\nWarning\n\n\nAdwords parsing is still experimental!\n\n\n\n\n    $adwordsResults = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        // do stuff\n    }\n\n\n\n\nAdwords sections\n\n\nAdwords results are composed from 3 distinct sections. These sections can be at the top, at the right or at the bottom\nof the natural results. See the schema:\n\n\n\n\nBy default all results are available in the result set, if you need \nto get results from a section, you can use the section as a type filter:\n\n\n    use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n    $adwordsResults = $response->getAdwordsResults();\n\n    $topResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_TOP);\n    $rightResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_RIGHT);\n    $bottomResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_BOTTOM);\n\n    foreach($topResults as $result){\n        // Do stuff...\n    }\n\n\n\n\nAdwords Types\n\n\nAd\n\n\nAds results are the basics results from adwords.\n\n\n\n\nAvailable with\n\n\n\n\nAdwordsResultType::AD\n\n\n\n\nData\n\n\n\n\ntitle\n \nstring\n \n[A]\n\n\nurl\n \nstring\n: The url reach when clicking the title\n\n\nvisurl\n \nstring\n \n[B]\n: The visual url\n\n\ndescription\nstring\n \n[C]\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n\n    $results = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        if($result->is(AdwordsResultType::AD)){\n            $url = $result->url;\n        }\n    }\n\n\n\n\nShopping\n\n\nThese are the results from google shopping/merchant.\n\n\n\n\nAvailable with\n\n\n\n\nAdwordsResultType::SHOPPING_GROUP\n\n\n\n\nData\n\n\n\n\nproducts\n \narray\n: The product list. Each product contains the following items:\n\n\ntitle\n \nstring\n \n[A]\n\n\nimage\n \nstring\n \n[B]\n: the image as specified by google - either an image url or a base64 encoded image\n\n\nurl\n \nstring\n: The url reached when clicking the title\n\n\ntarget\n \nstring\n \n[C]\n: The target website as shown by google\n\n\nprice\nstring\n \n[D]\n: The price as show by google\n\n\n\n\n\n\n\n\nExample\n\n\n    use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n    $results = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        if($result->is(AdwordsResultType::SHOPPING_GROUP)){\n            foreach($result->products as $item){\n                $title = $item->title;\n            }\n        }\n    }\n\n\n\n\nAdditional info\n\n\nA Google SERP contains even more information that the result list. Sometime they will be very helpful to get the\nmost from the SERP.\n\n\nHere is the list of these info currently supported by the parser.\n\n\nNumber of results\n\n\n\n\nRepresents the total number of results returned by the current search. \nThe format of this number can change from country to country (61,000,000 or 61 000 000 or 6,10,00,000 etc...) \nWe take care of returning this number as a integer no matter the initial format.\n\n\nIn some cases this number is not available (for instance with mobile layout)\n\n\n    $numberOfResults = $response->getNumberOfResults();\n\n    if(null === $numberOfResults){\n        // D'oh!\n    } elseif($numberOfResults < 2000) {\n        // ...\n    } else {\n        // ...\n    }\n\n\n\n\nRelated searches\n\n\n\n\nGoogle uses to give a list of related searches at the bottom of the page. The method \ngetRelatedSearches\n will return a list of these items.\n\n\n    $relatedSearches = $response->getRelatedSearches();\n    foreach ($relatedSearches as $relatedSearch) {\n        $url = $relatedSearch->url;\n        $title = $relatedSearch->title;\n    }\n\n\n\n\nCustom parsing\n\n\nSometimes you need information that are not available in our parser. \n\n\nFirst of all, search if someone already asked for this feature \non the \nissue tracker\n. \n\n\nIf you don't find a trace of this feature, but you still consider that this feature is important, then open an issue and\nlet's discuss it. This is very important because if the feature is implemented in the library it will take advantage of\nbeing updated on google updates, and you wont have to maintain it.\n\n\n\n\nBack from the issue tracker, no one mentioned it and you still \nwant to parse the information by yourself\n.\n Alright, here are the tools you need.\n\n\nQuery with css\n\n\nThe easiest way to do it for a web developer: \nwith css\n.\n\n\n    $response = $googleClient->query($googleUrl);\n\n    // Returns \\DOMNodeList\n    $queryResult = $response->cssQuery('#someId');\n\n    if ($queryResult->length == 1) {\n        // You can query again to find items in the previous context.\n\n        // Gets all items with the class 'someClass' within the element with the id 'someId'\n        $queryResult = $response->cssQuery('.someClass', $queryResult->item(0));\n    } else {\n        // some errors...\n    }\n\n\n\n\nIt works exactly as \nDOMXPath::query\n does. Actually the css is translated \nto xpath and \nDOMXPath::query\n is called on the dom element.\n\n\nQuery with xpath\n\n\nThat's very similar to the css way, except that you will use \nxpath\n.\n\n\n    $response = $googleClient->query($googleUrl);\n\n    $queryResult = $response->xpathQuery('descendant::div[@id=\"someId\"]');\n\n    if ($queryResult->length == 1) {\n        // Gets all 'a' tags inside the element with the id 'someId'.\n        $queryResult = $response->xpathQuery('a', $queryResult->item(0));\n    } else {\n        // some errors...\n    }\n\n\n\n\nThere is also a shortcut to the xpath object.\n\n\n    $response = $googleClient->query($googleUrl);\n\n    $xpath = $response->getXpath();\n    $xpath->query('someXpath');\n\n\n\n\nManipulate the DOM object\n\n\nYou can get the \nDOM object\n to manipulate it, or to save it in a file.\n\n\n    $response = $googleClient->query($googleUrl);\n\n    $dom = $response->getDom();\n\n    // Writes the dom content in the file 'file.html'\n    $dom->save('file.html');\n\n\n\n\n\n\nview also:\n\n\n\n\nConfigure the google client\n\n\nCreate urls\n\n\nHandle errors",
            "title": "Parse a Google Page"
        },
        {
            "location": "/search-engine/google/parse-page/#parse-a-google-page",
            "text": "The necessary documentation about parsing a google page   Back to the  general google documentation .   Parsing a page consists in the structured extraction of parts of the page. The end result is the ability to \nmake the distinction between these different parts and to gather details on them to show them in another fashion.   Important notice about google update  The following examples can change at any time.   As soon as google changes its page structure, you may need to update the library.\nYou can  watch the repository on github \nto be warned of new releases as they come.    A google SERP can contain different type of result.\nFirstly they are divided in three distinct regions:  natural  (organic),  paid  (adwords) and  graph results  and each of them\nhas its own results types. Graph result are  not supported  by the library.  There is a great diversity of results and the library gives you the api to work with them, here we document\nhow you will work with.",
            "title": "Parse a Google Page"
        },
        {
            "location": "/search-engine/google/parse-page/#natural-results",
            "text": "Natural results (aka organic results) are main results of the page.  Each natural result has a position and some available data. You can access them the following way (see the foreach loop):      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleClient = new GoogleClient($httpClient);\n\n    $googleUrl = new GoogleUrl();\n    $google->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        // Here we iterate over the result list\n        // Each result will have different data based on its type\n    }  Each of the result from the loop will have the following methods available:   getTypes() : the types of the result  is($type) : check if the result is of the given type  getDataValue($type) : Get the given data from the result. Everything accessible with  getDataValue \nis also accessible with a property, e.g the two examples do the same thing:  $result->getDataValue('url')  and  $result->url  getData() : Get the all the data of the result  getOnPagePosition() : Get the position of the result on the page (starting at 1)  getRealPosition() : Get the global position of the result (starting at 1), that means it is aware of the pagination.  Be aware  that in some circumstances this number can be wrong because google might show more results on the previous pages.   The difference between each result type is the list of data available with  getDataValue($type)  and  getData() .\nSee bellow for all available data per result type.  Natural Result Types  Result types  can be accessed through the class  NaturalResultType ,      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    if($result->is(NaturalResultType::CLASSICAL)){\n        // Do stuff\n    }\n\n    // You can also check many types at once\n    // Here we check if the result is classical or image group\n\n    if($result->is(NaturalResultType::CLASSICAL, NaturalResultType::IMAGE_GROUP)){\n        // Do stuff\n    }  From the  resultSet  you can also access all the results matching one of the given type:      // Get all the results that are either classical or image_group\n    $results = $results->getResultsByType(NaturalResultType::CLASSICAL, NaturalResultType::IMAGE_GROUP);  Classical  These results are the common natural results that have always existed in google.   Available with   NaturalResultType::CLASSICAL   Data   title   string  [ A ]  url   string : the url targeted on clicking the title  destination   string  [ B ]: either a url or a breadcrumb-like destination  description   string  [ C ]  isAmp   boolean  true if the results is an  AMP  result   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL)){\n            $title = $result->title;\n            $url   = $result->url;\n        }\n    }  Classical Large  This type is an extension of the  classical result , with sitelinks in addition.   Mobile version (since version 0.2):    Available with   NaturalResultType::CLASSICAL_LARGE  NaturalResultType::CLASSICAL   Data   title   string  [ A ]  url   string : the url targeted on clicking the title  destination   string  [ B ]: either a url or a breadcrumb-like destination  description   string  [ C ]  sitelinks   array :  title   string  [ D ]  url   string : the url targeted on clicking the sitelink title  description   string  [ E ]     Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL_LARGE)){\n            $title = $result->title;\n            $url   = $result->url;\n            $sitelinks = $result->sitelinks;\n            foreach ($sitelinks as $sitelink) {\n                $sitelinkTitle = $sitelink->title;\n            }\n        }\n    }  Classical Video  This type an extension of the  classical result , but it refers to a video result.  The video result can be illustrated with either a thumbnail or a large image.   Available with   NaturalResultType::CLASSICAL_VIDEO  NaturalResultType::CLASSICAL   Data   title   string  [ A ]  url   string : the url targeted on clicking the title  destination   string  [ B ]: either a url or a breadcrumb-like destination  description   string  [ C ]  videoLarge   bool : true if the video is image is large (usually first result)  videoCover   Media Object : The video cover. Only if videoLarge is true   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::CLASSICAL_VIDEO)){\n            $title = $result->title;\n            if($result->videoLarge){\n                // ...\n            }\n        }\n    }  Classical Illustrated  Classical results might have an additional  CLASSICAL_ILLUSTRATED  type when the results is \nillustrated with a thumbnail. Non large video results have this type as well.  Available with   NaturalResultType::CLASSICAL_ILLUSTRATED   Data   thumb   Media Object : the thumbnail   Image Group  Images that appear as a group of results.   Mobile version (since version 0.2):   Available with   NaturalResultType::IMAGE_GROUP   Data   images   array : the list of images that compose the image group, each image contains:  sourceUrl   string : the url where the image was found  targetUrl string : the url reached on clicking the image  image   string : the image data as specified by google (either an image url or a base64 encoded image)    moreUrl   string : The url corresponding to the google image search  isCarousel   boolean : True if images have the form of a carousel (since version 0.2)   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::IMAGE_GROUP)){\n            foreach($result->images as $image){\n                $sourceUrl = $image->sourceUrl;\n            }\n        }\n    }  Video Group  This type is present on mobile results and was added with version  0.2 .   It shows some videos (usualy 10) arranged in a carousel.   Available with   NaturalResultType::VIDEO_GROUP   Data   videos   array : the list of images that compose the image group, each image contains:  title   string : Title of the video  url string : the url reached on clicking the item  image   Media object : image of the video     Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::VIDEO_GROUP)){\n            foreach($result->videos as $video){\n                $url = $video->url;\n            }\n        }\n    }  Map  A result illustrated by a map and that contains sub-results.   Available with   NaturalResultType::MAP   Data   localPack   array : The sub results for the map:  title   string   [A] : Name of the place  url string   [B] : Website of the sub-result  street   string   [C] : The address of the sub-result  stars   string   [D] : The rating of the result as a number  review   string   [E] : The review string as specified by google (e.g '1 review')  phone   string   [G] : The phone number    mapUrl   string   [F] : The url to access the map search   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::MAP)){\n            foreach($result->localPack as $place){\n                $website = $place->website;\n            }\n        }\n    }  Answer Box  Block that answers a question asked by the keywords.   Available with   NaturalResultType::ANSWER_BOX   Data   title   string  [ A ]  url   string : the url targeted on clicking the title  destination   string  [ B ]: either a url or a breadcrumb-like destination  description   string  [ C ]   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::ANSWER_BOX)){\n            $title = $result->title;\n            $url   = $result->url;\n        }\n    }  Knowledge  Since version 0.2.1  Knowledge boxes that appear among mobile results.   Be aware that knowledge results are only included if they are present among the result list. \nThat means that on non-mobile results knowledge results are not available because they are placed on the right \nof natural results.   Available with   NaturalResultType::KNOWLEDGE   Data   title   string  [ A ]  shortDescription   string  [ B ] nature of the element (character,    Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::KNOWLEDGE)){\n            $title = $result->title;\n            $description   = $result->shortDescription;\n        }\n    }  People Also Ask  Since version 0.2.3  List of questions that people also ask   Available with   NaturalResultType::PEOPLE_ALSO_ASK   Data   questions   array  question   string     Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::PEOPLE_ALSO_ASK)){\n            $questions = $result->questions;\n\n            foreach ($questions as $question) {\n                $questionText = $question->question;\n            }\n        }\n    }  Tweet Carousel  Recent tweet list from an user matching the search keywords.   Available with   NaturalResultType::TWEETS_CAROUSEL   Data   title   string   [A]  url   string : The url reach when clicking the title  user string : The author of the tweets   Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::TWEETS_CAROUSEL)){\n            $user = $result->user;\n        }\n    }  In the News  Recent news results.   These results do not exists anymore  In early 2017 Google deleted in the news results, they were replaced by \"top stories\" results.\nThese results are now deprecated and might be deleted from serps in future releases.    Available with   NaturalResultType::IN_THE_NEWS   Data   news   array  title   string   [A]  description   string   [B]  url string : The url reached when clicking the title     Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::IN_THE_NEWS)){\n            foreach($result->news as $news){\n                $newsTitle = $title;\n                $newsUrl = $url;\n            }\n        }\n    }  Top Stories  List of recent popular news.   Implemented in version  0.1.4  as a successor for \"in the news\"  Composed top stories for mobile were implemented with version  0.2.2     Top stories might be present in 3 distinctive formats:  carousel ,  vertical ,  composed .   Carousel   Vertical   Composed  (mobile)   Available with   NaturalResultType::TOP_STORIES  NaturalResultType::COMPOSED_TOP_STORIES   Note: all top stories have the type  NaturalResultType::TOP_STORIES . In addition of what composed top stories\nalso have  NaturalResultType::COMPOSED_TOP_STORIES .  Data   isCarousel   boolean : true when has a carousel  isVertical   boolean : true when has vertical items  news   array  title   string   [A]  url string : The url reached when clicking the title     Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::TOP_STORIES)){\n            foreach($result->news as $news){\n                $newsTitle = $title;\n                $newsUrl = $url;\n            }\n        }\n    }  About composed top stories  Composed top stories are mixing both of vertical and carousel news that appear on mobiles. \nThe composed results will have variables  isCarousel   and   isVertical  set to true.  When iterating over news you can check if the news is a carousel or a vertical result:      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    foreach($result->news as $news){\n        if ($news->is(NaturalResultType::TOP_STORIES_NEWS_CAROUSEL) {\n            // carousel\n        } elseif ($news->is(NaturalResultType::TOP_STORIES_NEWS_VERTICAL) {\n            // vertical\n        }\n    }  You can also distinctly get one of the result types:      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $carouselResults = $result->news->getResultsByType(NaturalResultType::TOP_STORIES_NEWS_CAROUSEL);  Flights  Flight sample from google flights   Available with   NaturalResultType::FLIGHTS   Data  No data is parsed from flight results. There is no plan to implement it because it's complex and not very useful.  Example      use Serps\\SearchEngine\\Google\\NaturalResultType;\n\n    $results = $response->getNaturalResults();\n\n    foreach($results as $result){\n        if($result->is(NaturalResultType::FLIGHTS)){\n            // Got a flight result\n        }\n    }",
            "title": "Natural Results"
        },
        {
            "location": "/search-engine/google/parse-page/#adwords-results",
            "text": "The google client offers an Adwords parser.   Warning  Adwords parsing is still experimental!       $adwordsResults = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        // do stuff\n    }  Adwords sections  Adwords results are composed from 3 distinct sections. These sections can be at the top, at the right or at the bottom\nof the natural results. See the schema:   By default all results are available in the result set, if you need \nto get results from a section, you can use the section as a type filter:      use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n    $adwordsResults = $response->getAdwordsResults();\n\n    $topResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_TOP);\n    $rightResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_RIGHT);\n    $bottomResults = $adwordsResults->getResultsByType(AdwordsResultType::SECTION_BOTTOM);\n\n    foreach($topResults as $result){\n        // Do stuff...\n    }  Adwords Types  Ad  Ads results are the basics results from adwords.   Available with   AdwordsResultType::AD   Data   title   string   [A]  url   string : The url reach when clicking the title  visurl   string   [B] : The visual url  description string   [C]   Example      use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n\n    $results = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        if($result->is(AdwordsResultType::AD)){\n            $url = $result->url;\n        }\n    }  Shopping  These are the results from google shopping/merchant.   Available with   AdwordsResultType::SHOPPING_GROUP   Data   products   array : The product list. Each product contains the following items:  title   string   [A]  image   string   [B] : the image as specified by google - either an image url or a base64 encoded image  url   string : The url reached when clicking the title  target   string   [C] : The target website as shown by google  price string   [D] : The price as show by google     Example      use Serps\\SearchEngine\\Google\\AdwordsResultType;\n\n    $results = $response->getAdwordsResults();\n\n    foreach($results as $result){\n        if($result->is(AdwordsResultType::SHOPPING_GROUP)){\n            foreach($result->products as $item){\n                $title = $item->title;\n            }\n        }\n    }",
            "title": "Adwords Results"
        },
        {
            "location": "/search-engine/google/parse-page/#additional-info",
            "text": "A Google SERP contains even more information that the result list. Sometime they will be very helpful to get the\nmost from the SERP.  Here is the list of these info currently supported by the parser.  Number of results   Represents the total number of results returned by the current search. \nThe format of this number can change from country to country (61,000,000 or 61 000 000 or 6,10,00,000 etc...) \nWe take care of returning this number as a integer no matter the initial format.  In some cases this number is not available (for instance with mobile layout)      $numberOfResults = $response->getNumberOfResults();\n\n    if(null === $numberOfResults){\n        // D'oh!\n    } elseif($numberOfResults < 2000) {\n        // ...\n    } else {\n        // ...\n    }  Related searches   Google uses to give a list of related searches at the bottom of the page. The method  getRelatedSearches  will return a list of these items.      $relatedSearches = $response->getRelatedSearches();\n    foreach ($relatedSearches as $relatedSearch) {\n        $url = $relatedSearch->url;\n        $title = $relatedSearch->title;\n    }",
            "title": "Additional info"
        },
        {
            "location": "/search-engine/google/parse-page/#custom-parsing",
            "text": "Sometimes you need information that are not available in our parser.   First of all, search if someone already asked for this feature \non the  issue tracker .   If you don't find a trace of this feature, but you still consider that this feature is important, then open an issue and\nlet's discuss it. This is very important because if the feature is implemented in the library it will take advantage of\nbeing updated on google updates, and you wont have to maintain it.   Back from the issue tracker, no one mentioned it and you still  want to parse the information by yourself .\n Alright, here are the tools you need.  Query with css  The easiest way to do it for a web developer:  with css .      $response = $googleClient->query($googleUrl);\n\n    // Returns \\DOMNodeList\n    $queryResult = $response->cssQuery('#someId');\n\n    if ($queryResult->length == 1) {\n        // You can query again to find items in the previous context.\n\n        // Gets all items with the class 'someClass' within the element with the id 'someId'\n        $queryResult = $response->cssQuery('.someClass', $queryResult->item(0));\n    } else {\n        // some errors...\n    }  It works exactly as  DOMXPath::query  does. Actually the css is translated \nto xpath and  DOMXPath::query  is called on the dom element.  Query with xpath  That's very similar to the css way, except that you will use  xpath .      $response = $googleClient->query($googleUrl);\n\n    $queryResult = $response->xpathQuery('descendant::div[@id=\"someId\"]');\n\n    if ($queryResult->length == 1) {\n        // Gets all 'a' tags inside the element with the id 'someId'.\n        $queryResult = $response->xpathQuery('a', $queryResult->item(0));\n    } else {\n        // some errors...\n    }  There is also a shortcut to the xpath object.      $response = $googleClient->query($googleUrl);\n\n    $xpath = $response->getXpath();\n    $xpath->query('someXpath');  Manipulate the DOM object  You can get the  DOM object  to manipulate it, or to save it in a file.      $response = $googleClient->query($googleUrl);\n\n    $dom = $response->getDom();\n\n    // Writes the dom content in the file 'file.html'\n    $dom->save('file.html');   view also:   Configure the google client  Create urls  Handle errors",
            "title": "Custom parsing"
        },
        {
            "location": "/search-engine/google/google-url/",
            "text": "Work with google urls\n\n\nSERPS gives you the tools you need to create urls for google.\n\n\n\n\nBack to the \ngeneral google documentation\n.\n\n\n\n\nThe class \nGoogleUrl\n offers many convenient tools to work with google urls. See how it works with examples.\n\n\nCreate an url\n\n\nThe url builder has the required tools to build an url from scratch.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n    $googleUrl->setLanguageRestriction('lang_en');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&lr=lang_en\n\n\n\n\nUrl from a string\n\n\nIt's also possible to parse an an existing google url string to an url object.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = GoogleUrl::fromString('https://google.com/search?q=simpsons');\n    echo $googleUrl->getSearchTerm();\n    // simpsons\n\n\n\n\nAdditionally you can continue to manipulate this url\n\n\n    $googleUrl->setLanguageRestriction('lang_en');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&lr=lang_en\n\n\n\n\nGoogle domain\n\n\nBy default an url is generated for \ngoogle.com\n but you can choose any domain of your choice:\n\n\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl('google.fr');\n    $googleUrl->setSearchTerm('simpsons');\n    echo $googleUrl->buildUrl();\n    // https://google.fr/search?q=simpsons\n\n\n\n\nIt's also possible to modify it latter\n\n\n    $googleUrl->setHost('google.de');\n    echo $googleUrl->buildUrl();\n    // https://google.de/search?q=simpsons\n\n\n\n\nAdd and remove parameters\n\n\nIt's possible to add or remove parameters\n\n\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'simpsons');\n    $googleUrl->setParam('start', 11);\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&start=11\n\n    $googleUrl->removeParam('start');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons\n\n\n\n\nRaw parameters\n\n\nBy default parameters are encoded for urls. For instance \n\"Homer Simpsons\"\n will become \n\"Homer+Simpsons\"\n\nbut \n\"Homer+Simpsons\"\n will become \n\"Homer%2BSimpson\"\n\n\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'Homer+Simpson');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=Homer%2BSimpson\n\n\n\n\nIt's possible to deal with raw params, this way the param will be passed to the url with no additional encoding. \nThat is achieved by passing true as the third argument of \nsetParam\n.\n\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'Homer+Simpson', true);\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=Homer+Simpson\n\n\n\n\nMore parameters\n\n\nSome parameters are very common and for some of them we created convenient shortcuts. See the list:\n\n\nsetSearchTerm\n\n\n$url->setSearchTerm($searchTerm)\n\n\nSets the keywords to search for. Modifies the value for the \nq\n parameter.\n\n\nsetPage\n\n\n$url->setPage($pageNumber)\n\n\nSets the page to parse (starts at 1). Modifies the value for the \nstart\n parameter.\n\n\n\n\nNote\n\n\nIf value is less than 1, the param \nstart\n will be removed from the url.\n\n\n\n\nsetResultsPerPage\n\n\n$url->setResultsPerPage($resultsPerPages)\n\n\nSets the number of results per pages (between 1 and 100). Modifies the value for the \nnum\n parameter.\n\n\nsetLanguageRestriction\n\n\n$url->setLanguageRestriction($lang)\n\n\nSets language of the results. Modifies the value for the \nlr\n parameter. e.g  \n\"lang_en\"\n. \n\n\n\n\nNote\n\n\n\"lang_\"\n will be automatically prepended if it is not present. \n\n\nThat means that \n$url->setLanguageRestriction('en')\n\nand \n$url->setLanguageRestriction('lang_en')\n do the same thing.\n\n\n\n\nsetAutoCorrectionEnabled\n\n\n$url->setAutoCorrectionEnabled($enabled)\n\n\nSets if the auto correction should be enabled (\ntrue\n or \nfalse\n). Modifies the value for the \nnfpr\n parameter.\n\n\n\n\nView also:\n\n\n\n\nConfigure the google client\n\n\nParse a google page\n\n\nHandle errors",
            "title": "Google Url"
        },
        {
            "location": "/search-engine/google/google-url/#work-with-google-urls",
            "text": "SERPS gives you the tools you need to create urls for google.   Back to the  general google documentation .   The class  GoogleUrl  offers many convenient tools to work with google urls. See how it works with examples.  Create an url  The url builder has the required tools to build an url from scratch.      use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n    $googleUrl->setLanguageRestriction('lang_en');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&lr=lang_en  Url from a string  It's also possible to parse an an existing google url string to an url object.      use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = GoogleUrl::fromString('https://google.com/search?q=simpsons');\n    echo $googleUrl->getSearchTerm();\n    // simpsons  Additionally you can continue to manipulate this url      $googleUrl->setLanguageRestriction('lang_en');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&lr=lang_en  Google domain  By default an url is generated for  google.com  but you can choose any domain of your choice:      use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl('google.fr');\n    $googleUrl->setSearchTerm('simpsons');\n    echo $googleUrl->buildUrl();\n    // https://google.fr/search?q=simpsons  It's also possible to modify it latter      $googleUrl->setHost('google.de');\n    echo $googleUrl->buildUrl();\n    // https://google.de/search?q=simpsons  Add and remove parameters  It's possible to add or remove parameters      use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'simpsons');\n    $googleUrl->setParam('start', 11);\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons&start=11\n\n    $googleUrl->removeParam('start');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=simpsons  Raw parameters  By default parameters are encoded for urls. For instance  \"Homer Simpsons\"  will become  \"Homer+Simpsons\" \nbut  \"Homer+Simpsons\"  will become  \"Homer%2BSimpson\"      use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'Homer+Simpson');\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=Homer%2BSimpson  It's possible to deal with raw params, this way the param will be passed to the url with no additional encoding. \nThat is achieved by passing true as the third argument of  setParam .      $googleUrl = new GoogleUrl();\n    $googleUrl->setParam('q', 'Homer+Simpson', true);\n    echo $googleUrl->buildUrl();\n    // https://google.com/search?q=Homer+Simpson  More parameters  Some parameters are very common and for some of them we created convenient shortcuts. See the list:  setSearchTerm  $url->setSearchTerm($searchTerm)  Sets the keywords to search for. Modifies the value for the  q  parameter.  setPage  $url->setPage($pageNumber)  Sets the page to parse (starts at 1). Modifies the value for the  start  parameter.   Note  If value is less than 1, the param  start  will be removed from the url.   setResultsPerPage  $url->setResultsPerPage($resultsPerPages)  Sets the number of results per pages (between 1 and 100). Modifies the value for the  num  parameter.  setLanguageRestriction  $url->setLanguageRestriction($lang)  Sets language of the results. Modifies the value for the  lr  parameter. e.g   \"lang_en\" .    Note  \"lang_\"  will be automatically prepended if it is not present.   That means that  $url->setLanguageRestriction('en') \nand  $url->setLanguageRestriction('lang_en')  do the same thing.   setAutoCorrectionEnabled  $url->setAutoCorrectionEnabled($enabled)  Sets if the auto correction should be enabled ( true  or  false ). Modifies the value for the  nfpr  parameter.   View also:   Configure the google client  Parse a google page  Handle errors",
            "title": "Work with google urls"
        },
        {
            "location": "/search-engine/google/handle-errors/",
            "text": "Handle erros from the google client\n\n\n\n\n\n\nBack to the \ngeneral google documentation\n.\n\n\n\n\nWorking with google involves to make http request, to get an output from google and to parse this output. \nAll of these steps are not error free, you can encounter a network error, an error from google server, get a captcha\nor even face some updated google serp not supported by your version of the library.\n\n\nErrors are managed with exceptions, that makes them easy to handle.\n\n\nRequest error\n\n\nThere are several reasons for a request error to trigger:\n\n\n\n\nA network error\n\n\nA http error\n\n\nA captcha error\n\n\n\n\nAll these errors can be grouped under the same exception type:\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\RequestErrorException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(RequestErrorException $e){\n        // Some error with the request\n        $errorInfo = $e->getMessage();\n    }\n\n\n\n\nIt's possible to make the distinction between each of them, see bellow.\n\n\nNetwork errors\n\n\nNetwork errors occur when it was not possible to create a valid http connexion with google. They use to be triggered\nby http client, and they can be different for each http client.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\NetworkErrorException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(NetworkErrorException $e){\n        // Something wrong happened with network\n        $errorInfo = $e->getMessage();\n    }\n\n\n\n\nInvalide Response\n\n\nA invalid response happens when the http server returned a invalid response (status code 404, 500...).\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\InvalidResponseException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(InvalidResponseException $e){\n        // Http response is not valid\n        $errorInfo = $e->getMessage();\n    }\n\n\n\n\nCaptcha errors\n\n\nA captcha error happens when the the server asks for a captcha to continue.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\CaptchaException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(CaptchaException $e){\n        // Captcha required\n        $errorInfo = $e->getMessage();\n    }\n\n\n\n\nDOM errors\n\n\nOnce you got the data from google, you are ready to parse the DOM, but you are not safe against google DOM updates,\nGoogle might have updated its DOM structure and your version of the library is maybe not updated. That's what DOM \nexceptions are made for.\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\SearchEngine\\Google\\Exception\\InvalidDOMException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    try{\n        $results = $response->getNaturalResults();\n\n        foreach($results as $result){\n            // parse results\n        }\n    }catch(InvalidDOMException $e){\n        // Something bad happened while parsing\n        // Maybe an update of the library is needed, \n        // the exception message maybe tells more\n        $errorInfo = $e->getMessage();\n    }\n\n\n\n\nMore complete example of error handling\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\RequestErrorException;\n    use Serps\\Exception\\RequestError\\HttpResponseErrorException;\n    use Serps\\Exception\\RequestError\\CaptchaException;\n    use Serps\\SearchEngine\\Google\\Exception\\InvalidDOMException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = null;\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(HttpResponseErrorException $e){\n        // Http response is not valid, maybe an error from google or your url\n        $errorInfo = $e->getMessage();\n    }catch(CaptchaException $e){\n        // Captcha needs to be solved\n    }catch(RequestErrorException $e){\n        // Other request error are handled here, maybe something wrong with your network\n        $errorInfo = $e->getMessage();\n    }\n\n    if($response){\n        try{\n            $results = $response->getNaturalResults();\n            foreach($results as $result){\n                // parse results\n            }\n        }catch(InvalidDOMException $e){\n            // Something bad happened while parsing\n            // Maybe an update of the library is needed, \n            // the exception message will tell more about\n            $errorInfo = $e->getMessage();\n        }\n    }\n\n\n\n\n\n\nView also:\n\n\n\n\nConfigure the google client\n\n\nCreate urls\n\n\nParse a google page",
            "title": "Handle Google error"
        },
        {
            "location": "/search-engine/google/handle-errors/#handle-erros-from-the-google-client",
            "text": "Back to the  general google documentation .   Working with google involves to make http request, to get an output from google and to parse this output. \nAll of these steps are not error free, you can encounter a network error, an error from google server, get a captcha\nor even face some updated google serp not supported by your version of the library.  Errors are managed with exceptions, that makes them easy to handle.",
            "title": "Handle erros from the google client"
        },
        {
            "location": "/search-engine/google/handle-errors/#request-error",
            "text": "There are several reasons for a request error to trigger:   A network error  A http error  A captcha error   All these errors can be grouped under the same exception type:      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\RequestErrorException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(RequestErrorException $e){\n        // Some error with the request\n        $errorInfo = $e->getMessage();\n    }  It's possible to make the distinction between each of them, see bellow.  Network errors  Network errors occur when it was not possible to create a valid http connexion with google. They use to be triggered\nby http client, and they can be different for each http client.      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\NetworkErrorException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(NetworkErrorException $e){\n        // Something wrong happened with network\n        $errorInfo = $e->getMessage();\n    }  Invalide Response  A invalid response happens when the http server returned a invalid response (status code 404, 500...).      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\InvalidResponseException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(InvalidResponseException $e){\n        // Http response is not valid\n        $errorInfo = $e->getMessage();\n    }  Captcha errors  A captcha error happens when the the server asks for a captcha to continue.      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\CaptchaException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(CaptchaException $e){\n        // Captcha required\n        $errorInfo = $e->getMessage();\n    }",
            "title": "Request error"
        },
        {
            "location": "/search-engine/google/handle-errors/#dom-errors",
            "text": "Once you got the data from google, you are ready to parse the DOM, but you are not safe against google DOM updates,\nGoogle might have updated its DOM structure and your version of the library is maybe not updated. That's what DOM \nexceptions are made for.      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\SearchEngine\\Google\\Exception\\InvalidDOMException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = $googleClient->query($googleUrl);\n\n    try{\n        $results = $response->getNaturalResults();\n\n        foreach($results as $result){\n            // parse results\n        }\n    }catch(InvalidDOMException $e){\n        // Something bad happened while parsing\n        // Maybe an update of the library is needed, \n        // the exception message maybe tells more\n        $errorInfo = $e->getMessage();\n    }",
            "title": "DOM errors"
        },
        {
            "location": "/search-engine/google/handle-errors/#more-complete-example-of-error-handling",
            "text": "use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n    use Serps\\Exception\\RequestError\\RequestErrorException;\n    use Serps\\Exception\\RequestError\\HttpResponseErrorException;\n    use Serps\\Exception\\RequestError\\CaptchaException;\n    use Serps\\SearchEngine\\Google\\Exception\\InvalidDOMException;\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $googleUrl = new GoogleUrl();\n    $googleUrl->setSearchTerm('simpsons');\n\n    $response = null;\n\n    try{\n        $response = $googleClient->query($googleUrl);\n    }catch(HttpResponseErrorException $e){\n        // Http response is not valid, maybe an error from google or your url\n        $errorInfo = $e->getMessage();\n    }catch(CaptchaException $e){\n        // Captcha needs to be solved\n    }catch(RequestErrorException $e){\n        // Other request error are handled here, maybe something wrong with your network\n        $errorInfo = $e->getMessage();\n    }\n\n    if($response){\n        try{\n            $results = $response->getNaturalResults();\n            foreach($results as $result){\n                // parse results\n            }\n        }catch(InvalidDOMException $e){\n            // Something bad happened while parsing\n            // Maybe an update of the library is needed, \n            // the exception message will tell more about\n            $errorInfo = $e->getMessage();\n        }\n    }   View also:   Configure the google client  Create urls  Parse a google page",
            "title": "More complete example of error handling"
        },
        {
            "location": "/search-engine/google/client-configuration/",
            "text": "Google Client Configuration\n\n\n\n\n\n\n\n\n\nBack to the \ngeneral google documentation\n.\n\n\n\n\nQuery google\n\n\nTo query google you need to have a working google client. \n\n\nWhen a query is emitted by the google client there are 2 main components involved: a \nbrowser\n \nthat serves to create the http request and a \ngoogle url\n.\n\n\nHere is a bare example of how it works:\n\n\n\nuse Serps\\SearchEngine\\Google\\GoogleClient;\nuse Serps\\HttpClient\\CurlClient;\nuse Serps\\SearchEngine\\Google\\GoogleUrl;\nuse Serps\\Core\\Browser\\Browser;\n\n// 1. First you need to create a browser instance\n\n$browser = new Browser(new CurlClient());\n\n\n// 2. Then we create an google url for the search term \"simpsons\"\n\n$googleUrl = new GoogleUrl();\n$googleUrl->setSearchTerm('simpsons');\n\n\n// 3. We create a google client with our browser\n\n$googleClient = new GoogleClient($browser);\n\n// 4. Finally we send the query to google with our url\n\n$googleData = $googleClient->query($googleUrl);\n\n\n\n\n\nNote that you are not required to give a browser when creating the googleClient and you can only specify it \nat request time. In this case steps 3 and 4 become:\n\n\n\n// 3. We create a google client without the browser\n\n$googleClient = new GoogleClient();\n\n// 4. Finally we send the query to google with our url and our browser\n\n$googleData = $googleClient->query($googleUrl, $browser);\n\n\n\n\n\nConfigure the request (proxy, cookies...)\n\n\nAt the first release of the google client it was possible to modify user agent, proxy, language headers and cookies \non the google client. For better management of requests all this logic has moved on the browser since version \n0.2\n. \nTo learn more on this configuration, visit the  \nbrowser documentation\n.\n\n\n\n\nNext step: \nparse a page",
            "title": "Configure Google Client"
        },
        {
            "location": "/search-engine/google/client-configuration/#google-client-configuration",
            "text": "Back to the  general google documentation .",
            "title": "Google Client Configuration"
        },
        {
            "location": "/search-engine/google/client-configuration/#query-google",
            "text": "To query google you need to have a working google client.   When a query is emitted by the google client there are 2 main components involved: a  browser  \nthat serves to create the http request and a  google url .  Here is a bare example of how it works:  \nuse Serps\\SearchEngine\\Google\\GoogleClient;\nuse Serps\\HttpClient\\CurlClient;\nuse Serps\\SearchEngine\\Google\\GoogleUrl;\nuse Serps\\Core\\Browser\\Browser;\n\n// 1. First you need to create a browser instance\n\n$browser = new Browser(new CurlClient());\n\n\n// 2. Then we create an google url for the search term \"simpsons\"\n\n$googleUrl = new GoogleUrl();\n$googleUrl->setSearchTerm('simpsons');\n\n\n// 3. We create a google client with our browser\n\n$googleClient = new GoogleClient($browser);\n\n// 4. Finally we send the query to google with our url\n\n$googleData = $googleClient->query($googleUrl);  Note that you are not required to give a browser when creating the googleClient and you can only specify it \nat request time. In this case steps 3 and 4 become:  \n// 3. We create a google client without the browser\n\n$googleClient = new GoogleClient();\n\n// 4. Finally we send the query to google with our url and our browser\n\n$googleData = $googleClient->query($googleUrl, $browser);",
            "title": "Query google"
        },
        {
            "location": "/search-engine/google/client-configuration/#configure-the-request-proxy-cookies",
            "text": "At the first release of the google client it was possible to modify user agent, proxy, language headers and cookies \non the google client. For better management of requests all this logic has moved on the browser since version  0.2 . \nTo learn more on this configuration, visit the   browser documentation .   Next step:  parse a page",
            "title": "Configure the request (proxy, cookies...)"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/",
            "text": "Migration from v0.1 to v0.2\n\n\nVersion 0.2 overview\n\n\nThe version 0.2 brings some improvements that target the future of the library. \n\n\n\n\nSome parts from google package are moved to core package (like css parser)\nin order to make them ready for implementing new search engines. These change should be invisible to you.\n\n\nIt makes browser emulation more transparent by implementing a browser class that aims to mimic real browsers.\n\n\nGoogle client in now able to \nparse mobile results\n\n\nUrl interface was refactored to be more flexible.\n\n\nWe started to review tools to work with captcha in next releases.\n\n\nThere are also other changes, see the following guide for a review of the upgrade.\n\n\n\n\nThe following guide is aimed to help you to upgrade to v0.2, if you encounter any problem during the upgrade, the\ncommunity might help you on the gitter chat room, just ask!\n\n\nThe version 0.1 is now deprecated and wont be maintained anymore.\n\n\nDependencies\n\n\nCss parser moved from google package to core:\n\n\n\n\nserps/search-engine-google\n does not depend on \nsymfony/css-selector\n anymore\n\n\nserps/core\n now depends on \nsymfony/css-selector:^2|^3\n\n\n\n\nRemove PSR-7 implementation:\n\n\n\n\nserps/search-engine-google\n does not depend on \nzendframework/zend-diactoros\n anymore,\ninstead you need to add either \nzendframework/zend-diactoros\n or \nguzzlehttp/psr7\n to your dependency. \n\n\n\n\nRequest Builder\n\n\nBeing said in the previous paragraph, serps does not provide a PSR-7 implementation anymore. Until now we forced the\nusers to use zend-diactoros, now the choice of the PSR-7 implementation will be up to the user. \nThe goal was to let user choose what implementation to depend on. To make it worth serps now provides \na request builder that will automatically detect what package is installed in your dependencies and create\na request object for you:\n\n\n    use Serps\\Core\\Psr7\\RequestBuilder;\n\n    $request = RequestBuilder::buildRequest('http://foo.bar', 'GET');\n\n\n\n\nIn most cases this API change will be invisible to you, except that you need to add a psr7 dependency by yourself.\n\n\nGoogle: client update\n\n\nThis is probably the most sensible change from the upgrade. The google client changed the way it builds requests.\n\n\nInstead of giving it a \nhttp client\n at construction and \nproxy\n and \ncookie jar\n at request time, you will now\ngive it a default browser instance that wraps all of these three items and that can be overriden at request time.\nIn other words the constructor moved from \n\n\n    new GoogleClient(HttpClientInterface $client)\n\n\n\n\nto \n\n\n    new GoogleClient(BrowserInterface $browser = null)\n\n\n\n\nAnd the query method moved from \n\n\n    GoogleClient::query(GoogleUrlInterface $googleUrl, Proxy $proxy = null, CookieJarInterface $cookieJar = null)\n\n\n\n\nto \n\n\n    GoogleClient::query(GoogleUrlInterface $googleUrl, BrowserInterface $browser = null)\n\n\n\n\nIn addition property \n$googleClient->request\n  and method \nGoogleClient::getRequestBuilder()\n do not exist anymore,\nthey are fully replaced by the browser implementation.\n\n\nThe reason of this change is that google client was managing the request by itself. Making it hard to keep a consistent\nbrowser behaviour from different places and that was an issue for managing captcha that need to have the same\nbrowser environment (user-agent string, cookies, proxy...).\n\n\nNow the google client acts more like a real browser, leaving all the request logic to the browser and it will only\nmanage the url given to the browser and the response returned from the browser.\n\n\nHere is an example of how to use it before and after.\n\n\nBefore:\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $userAgent = \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\";\n    $googleClient->request->setUserAgent($userAgent);\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $response = $googleClient->query($googleUrl, $someProxy, $someCookies);\n\n\n\n\nAfter:\n\n\n    use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\Core\\Browser\\Browser;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $userAgent = 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36';\n    $language = 'en-US,en;q=0.8';\n\n    $browser = new Browser(new CurlClient(), $userAgent, $language, $someProxy, $someCookies);\n\n    $googleClient = new GoogleClient($browser);\n    $response = $googleClient->query($googleUrl);\n\n    // Alternatively you can pass browser at request time:\n    $googleClient = new GoogleClient();\n    $response = $googleClient->query($googleUrl, $browser);\n\n\n\n\nAs you can see the browser instance manages most of what a real browser would manage (at least for request):\n\n\n\n\nUser agent string\n\n\nLanguage headers (in previous version that was automatically set from the language detected in the google url) \n\n\nAdditional headers\n\n\nProxy\n\n\nCookie\n\n\n\n\n\n\nWarning\n\n\nAlthough the class is named \nBrowser\n it does not mean that it will parse the css and javascript of the page.\nThe name browser was chosen because it's an object that encapsulates all the request logic and that is able to \nmanage cookies and proxies as a real browser would do. \n\n\nIn any case\n this class is capable to parse javascript and css or to render the html by itself .\n\n\n\n\nGoogle: support for mobile results\n\n\nGoogle is now able to parse mobile results. All the mobile have been implemented in the same way as the other results\nand that should be invisible to you except that now you can parse mobile pages. \nThe \ngoogle parse guide\n was updated with new mobile results\n\n\nGoogle: CSS Parser\n\n\nThe css parser is not available from google package anymore, if you were using it you will need to rely on the \nreplacement from the core package.\n\n\nBefore:\n\n\nSerps\\SearchEngine\\Google\\Css:::toXPath('.expression');\n\n\n\n\nAfter:\n\n\nSerps\\Core\\Dom\\Css:::toXPath('.expression');\n\n\n\n\nGoogle: image results\n\n\nThanks to the recent addition of the \n\nMediaInterface\n \nserps makes it easy to work with image results parsed \nfrom google. \n\n\nWith the previous version image result format was unpredictable: that could be an url, or a base64 image... \nnow you wont have to care anymore about this. The only thing in you need to care about is how to store the image.\n\n\nConcretely the media interface will detect for you the type of image and gives you the possibility to get it\neither as a stream, as binary data or as a base64 string or to save it in a file:\n\n\n    $result->image->saveFile('myImage.png');\n\n\n\n\nGoogle: drop support for raw parser\n\n\nAt the very beginning of serps we though it would make sense to provide a raw parser for raw google pages \n(no-javascript pages), but there is actually no use for it. Even the results from curl are the same as the javascript ones\nand this is due to the fact that the page needs to be evaluated to show a javascript disabled version (curl does \nnot evaluate the page, thus it returns almost the same version as the javascript-enabled one).\n\n\nMaintaining a raw parser was a lot of efforts for a very few results. We simply decided to drop support for the raw parser.\n\n\nGoogle: additional changes:\n\n\n\n\nSerps\\SearchEngine\\Google\\GoogleDom\n now extends \nSerps\\Core\\Dom\\WebPage\n \n\n\nSerps\\SearchEngine\\Google\\GoogleError\n now extends \nSerps\\Core\\Dom\\WebPage\n \n    and does not extend \nSerps\\SearchEngine\\Google\\GoogleDom\n anymore\n\n\nGoogle cards results are now supported\n\n\nMobile page detection: GoogleSerp::isMobile() \n\n\nMobile results have now their own parser\n\n\nLarge video have the CLASSICAL type as mentioned in the doc (bugfix)\n\n\n\n\nURL\n\n\nThe url interface changed. Most of the changes are internal and you should not be concerned by it.\n\n\nIn case you played with the url, \nsee the \ncore changelog\n for more details\n\n\nCookie expiration time\n\n\nCookie expiration time was not standard and was invalid most of time. Now cookie expiration is correctly managed.",
            "title": "migration 0.2"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#migration-from-v01-to-v02",
            "text": "",
            "title": "Migration from v0.1 to v0.2"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#version-02-overview",
            "text": "The version 0.2 brings some improvements that target the future of the library.    Some parts from google package are moved to core package (like css parser)\nin order to make them ready for implementing new search engines. These change should be invisible to you.  It makes browser emulation more transparent by implementing a browser class that aims to mimic real browsers.  Google client in now able to  parse mobile results  Url interface was refactored to be more flexible.  We started to review tools to work with captcha in next releases.  There are also other changes, see the following guide for a review of the upgrade.   The following guide is aimed to help you to upgrade to v0.2, if you encounter any problem during the upgrade, the\ncommunity might help you on the gitter chat room, just ask!  The version 0.1 is now deprecated and wont be maintained anymore.",
            "title": "Version 0.2 overview"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#dependencies",
            "text": "Css parser moved from google package to core:   serps/search-engine-google  does not depend on  symfony/css-selector  anymore  serps/core  now depends on  symfony/css-selector:^2|^3   Remove PSR-7 implementation:   serps/search-engine-google  does not depend on  zendframework/zend-diactoros  anymore,\ninstead you need to add either  zendframework/zend-diactoros  or  guzzlehttp/psr7  to your dependency.",
            "title": "Dependencies"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#request-builder",
            "text": "Being said in the previous paragraph, serps does not provide a PSR-7 implementation anymore. Until now we forced the\nusers to use zend-diactoros, now the choice of the PSR-7 implementation will be up to the user. \nThe goal was to let user choose what implementation to depend on. To make it worth serps now provides \na request builder that will automatically detect what package is installed in your dependencies and create\na request object for you:      use Serps\\Core\\Psr7\\RequestBuilder;\n\n    $request = RequestBuilder::buildRequest('http://foo.bar', 'GET');  In most cases this API change will be invisible to you, except that you need to add a psr7 dependency by yourself.",
            "title": "Request Builder"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-client-update",
            "text": "This is probably the most sensible change from the upgrade. The google client changed the way it builds requests.  Instead of giving it a  http client  at construction and  proxy  and  cookie jar  at request time, you will now\ngive it a default browser instance that wraps all of these three items and that can be overriden at request time.\nIn other words the constructor moved from       new GoogleClient(HttpClientInterface $client)  to       new GoogleClient(BrowserInterface $browser = null)  And the query method moved from       GoogleClient::query(GoogleUrlInterface $googleUrl, Proxy $proxy = null, CookieJarInterface $cookieJar = null)  to       GoogleClient::query(GoogleUrlInterface $googleUrl, BrowserInterface $browser = null)  In addition property  $googleClient->request   and method  GoogleClient::getRequestBuilder()  do not exist anymore,\nthey are fully replaced by the browser implementation.  The reason of this change is that google client was managing the request by itself. Making it hard to keep a consistent\nbrowser behaviour from different places and that was an issue for managing captcha that need to have the same\nbrowser environment (user-agent string, cookies, proxy...).  Now the google client acts more like a real browser, leaving all the request logic to the browser and it will only\nmanage the url given to the browser and the response returned from the browser.  Here is an example of how to use it before and after.  Before:      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $userAgent = \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\";\n    $googleClient->request->setUserAgent($userAgent);\n\n    $googleClient = new GoogleClient(new CurlClient());\n\n    $response = $googleClient->query($googleUrl, $someProxy, $someCookies);  After:      use Serps\\SearchEngine\\Google\\GoogleClient;\n    use Serps\\HttpClient\\CurlClient;\n    use Serps\\Core\\Browser\\Browser;\n    use Serps\\SearchEngine\\Google\\GoogleUrl;\n\n    $userAgent = 'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36';\n    $language = 'en-US,en;q=0.8';\n\n    $browser = new Browser(new CurlClient(), $userAgent, $language, $someProxy, $someCookies);\n\n    $googleClient = new GoogleClient($browser);\n    $response = $googleClient->query($googleUrl);\n\n    // Alternatively you can pass browser at request time:\n    $googleClient = new GoogleClient();\n    $response = $googleClient->query($googleUrl, $browser);  As you can see the browser instance manages most of what a real browser would manage (at least for request):   User agent string  Language headers (in previous version that was automatically set from the language detected in the google url)   Additional headers  Proxy  Cookie    Warning  Although the class is named  Browser  it does not mean that it will parse the css and javascript of the page.\nThe name browser was chosen because it's an object that encapsulates all the request logic and that is able to \nmanage cookies and proxies as a real browser would do.   In any case  this class is capable to parse javascript and css or to render the html by itself .",
            "title": "Google: client update"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-support-for-mobile-results",
            "text": "Google is now able to parse mobile results. All the mobile have been implemented in the same way as the other results\nand that should be invisible to you except that now you can parse mobile pages. \nThe  google parse guide  was updated with new mobile results",
            "title": "Google: support for mobile results"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-css-parser",
            "text": "The css parser is not available from google package anymore, if you were using it you will need to rely on the \nreplacement from the core package.  Before:  Serps\\SearchEngine\\Google\\Css:::toXPath('.expression');  After:  Serps\\Core\\Dom\\Css:::toXPath('.expression');",
            "title": "Google: CSS Parser"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-image-results",
            "text": "Thanks to the recent addition of the  MediaInterface  \nserps makes it easy to work with image results parsed \nfrom google.   With the previous version image result format was unpredictable: that could be an url, or a base64 image... \nnow you wont have to care anymore about this. The only thing in you need to care about is how to store the image.  Concretely the media interface will detect for you the type of image and gives you the possibility to get it\neither as a stream, as binary data or as a base64 string or to save it in a file:      $result->image->saveFile('myImage.png');",
            "title": "Google: image results"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-drop-support-for-raw-parser",
            "text": "At the very beginning of serps we though it would make sense to provide a raw parser for raw google pages \n(no-javascript pages), but there is actually no use for it. Even the results from curl are the same as the javascript ones\nand this is due to the fact that the page needs to be evaluated to show a javascript disabled version (curl does \nnot evaluate the page, thus it returns almost the same version as the javascript-enabled one).  Maintaining a raw parser was a lot of efforts for a very few results. We simply decided to drop support for the raw parser.",
            "title": "Google: drop support for raw parser"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#google-additional-changes",
            "text": "Serps\\SearchEngine\\Google\\GoogleDom  now extends  Serps\\Core\\Dom\\WebPage    Serps\\SearchEngine\\Google\\GoogleError  now extends  Serps\\Core\\Dom\\WebPage  \n    and does not extend  Serps\\SearchEngine\\Google\\GoogleDom  anymore  Google cards results are now supported  Mobile page detection: GoogleSerp::isMobile()   Mobile results have now their own parser  Large video have the CLASSICAL type as mentioned in the doc (bugfix)",
            "title": "Google: additional changes:"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#url",
            "text": "The url interface changed. Most of the changes are internal and you should not be concerned by it.  In case you played with the url, \nsee the  core changelog  for more details",
            "title": "URL"
        },
        {
            "location": "/about/migration/from-v0_1-to-v0_2/#cookie-expiration-time",
            "text": "Cookie expiration time was not standard and was invalid most of time. Now cookie expiration is correctly managed.",
            "title": "Cookie expiration time"
        }
    ]
}